&&&& RUNNING TensorRT.trtexec [TensorRT v8600] # trtexec --onnx=model/resnet50int8/fuser.onnx --fp16 --int8 --inputIOFormats=fp16:chw,fp16:chw, --outputIOFormats=fp16:chw, --saveEngine=model/resnet50int8/build/fuser.plan --memPoolSize=workspace:2048 --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed --exportLayerInfo=model/resnet50int8/build/fuser.json
[12/14/2023-17:13:53] [I] === Model Options ===
[12/14/2023-17:13:53] [I] Format: ONNX
[12/14/2023-17:13:53] [I] Model: model/resnet50int8/fuser.onnx
[12/14/2023-17:13:53] [I] Output:
[12/14/2023-17:13:53] [I] === Build Options ===
[12/14/2023-17:13:53] [I] Max batch: explicit batch
[12/14/2023-17:13:53] [I] Memory Pools: workspace: 2048 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[12/14/2023-17:13:53] [I] minTiming: 1
[12/14/2023-17:13:53] [I] avgTiming: 8
[12/14/2023-17:13:53] [I] Precision: FP32+FP16+INT8
[12/14/2023-17:13:53] [I] LayerPrecisions: 
[12/14/2023-17:13:53] [I] Layer Device Types: 
[12/14/2023-17:13:53] [I] Calibration: Dynamic
[12/14/2023-17:13:53] [I] Refit: Disabled
[12/14/2023-17:13:53] [I] Version Compatible: Disabled
[12/14/2023-17:13:53] [I] TensorRT runtime: full
[12/14/2023-17:13:53] [I] Lean DLL Path: 
[12/14/2023-17:13:53] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[12/14/2023-17:13:53] [I] Exclude Lean Runtime: Disabled
[12/14/2023-17:13:53] [I] Sparsity: Disabled
[12/14/2023-17:13:53] [I] Safe mode: Disabled
[12/14/2023-17:13:53] [I] DirectIO mode: Disabled
[12/14/2023-17:13:53] [I] Restricted mode: Disabled
[12/14/2023-17:13:53] [I] Skip inference: Disabled
[12/14/2023-17:13:53] [I] Save engine: model/resnet50int8/build/fuser.plan
[12/14/2023-17:13:53] [I] Load engine: 
[12/14/2023-17:13:53] [I] Profiling verbosity: 2
[12/14/2023-17:13:53] [I] Tactic sources: Using default tactic sources
[12/14/2023-17:13:53] [I] timingCacheMode: local
[12/14/2023-17:13:53] [I] timingCacheFile: 
[12/14/2023-17:13:53] [I] Heuristic: Disabled
[12/14/2023-17:13:53] [I] Preview Features: Use default preview flags.
[12/14/2023-17:13:53] [I] MaxAuxStreams: -1
[12/14/2023-17:13:53] [I] BuilderOptimizationLevel: 3
[12/14/2023-17:13:53] [I] Input(s): fp16:chw
[12/14/2023-17:13:53] [I] Input(s): fp16:chw
[12/14/2023-17:13:53] [I] Output(s): fp16:chw
[12/14/2023-17:13:53] [I] Input build shapes: model
[12/14/2023-17:13:53] [I] Input calibration shapes: model
[12/14/2023-17:13:53] [I] === System Options ===
[12/14/2023-17:13:53] [I] Device: 0
[12/14/2023-17:13:53] [I] DLACore: 
[12/14/2023-17:13:53] [I] Plugins:
[12/14/2023-17:13:53] [I] setPluginsToSerialize:
[12/14/2023-17:13:53] [I] dynamicPlugins:
[12/14/2023-17:13:53] [I] ignoreParsedPluginLibs: 0
[12/14/2023-17:13:53] [I] 
[12/14/2023-17:13:53] [I] === Inference Options ===
[12/14/2023-17:13:53] [I] Batch: Explicit
[12/14/2023-17:13:53] [I] Input inference shapes: model
[12/14/2023-17:13:53] [I] Iterations: 10
[12/14/2023-17:13:53] [I] Duration: 3s (+ 200ms warm up)
[12/14/2023-17:13:53] [I] Sleep time: 0ms
[12/14/2023-17:13:53] [I] Idle time: 0ms
[12/14/2023-17:13:53] [I] Inference Streams: 1
[12/14/2023-17:13:53] [I] ExposeDMA: Disabled
[12/14/2023-17:13:53] [I] Data transfers: Enabled
[12/14/2023-17:13:53] [I] Spin-wait: Disabled
[12/14/2023-17:13:53] [I] Multithreading: Disabled
[12/14/2023-17:13:53] [I] CUDA Graph: Disabled
[12/14/2023-17:13:53] [I] Separate profiling: Enabled
[12/14/2023-17:13:53] [I] Time Deserialize: Disabled
[12/14/2023-17:13:53] [I] Time Refit: Disabled
[12/14/2023-17:13:53] [I] NVTX verbosity: 2
[12/14/2023-17:13:53] [I] Persistent Cache Ratio: 0
[12/14/2023-17:13:53] [I] Inputs:
[12/14/2023-17:13:53] [I] === Reporting Options ===
[12/14/2023-17:13:53] [I] Verbose: Enabled
[12/14/2023-17:13:53] [I] Averages: 10 inferences
[12/14/2023-17:13:53] [I] Percentiles: 90,95,99
[12/14/2023-17:13:53] [I] Dump refittable layers:Disabled
[12/14/2023-17:13:53] [I] Dump output: Disabled
[12/14/2023-17:13:53] [I] Profile: Enabled
[12/14/2023-17:13:53] [I] Export timing to JSON file: 
[12/14/2023-17:13:53] [I] Export output to JSON file: 
[12/14/2023-17:13:53] [I] Export profile to JSON file: 
[12/14/2023-17:13:53] [I] 
[12/14/2023-17:13:53] [I] === Device Information ===
[12/14/2023-17:13:53] [I] Selected Device: NVIDIA GeForce RTX 3080 Ti
[12/14/2023-17:13:53] [I] Compute Capability: 8.6
[12/14/2023-17:13:53] [I] SMs: 80
[12/14/2023-17:13:53] [I] Device Global Memory: 12023 MiB
[12/14/2023-17:13:53] [I] Shared Memory per SM: 100 KiB
[12/14/2023-17:13:53] [I] Memory Bus Width: 384 bits (ECC disabled)
[12/14/2023-17:13:53] [I] Application Compute Clock Rate: 1.695 GHz
[12/14/2023-17:13:53] [I] Application Memory Clock Rate: 9.501 GHz
[12/14/2023-17:13:53] [I] 
[12/14/2023-17:13:53] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[12/14/2023-17:13:53] [I] 
[12/14/2023-17:13:53] [I] TensorRT version: 8.6.0
[12/14/2023-17:13:53] [I] Loading standard plugins
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::fMHA_V2 version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::fMHCA version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::GroupNorm version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::LayerNorm version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ModulatedDeformConv2d version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Proposal version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::SeqLen2Spatial version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::SplitGeLU version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::Split version 1
[12/14/2023-17:13:53] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[12/14/2023-17:13:54] [I] [TRT] [MemUsageChange] Init CUDA: CPU +352, GPU +0, now: CPU 367, GPU 5427 (MiB)
[12/14/2023-17:13:54] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.6.0
[12/14/2023-17:13:54] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.6.0
[12/14/2023-17:13:59] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1209, GPU +249, now: CPU 1652, GPU 5720 (MiB)
[12/14/2023-17:13:59] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[12/14/2023-17:13:59] [I] Start parsing network model.
[12/14/2023-17:13:59] [I] [TRT] ----------------------------------------------------------------
[12/14/2023-17:13:59] [I] [TRT] Input filename:   model/resnet50int8/fuser.onnx
[12/14/2023-17:13:59] [I] [TRT] ONNX IR version:  0.0.7
[12/14/2023-17:13:59] [I] [TRT] Opset version:    13
[12/14/2023-17:13:59] [I] [TRT] Producer name:    pytorch
[12/14/2023-17:13:59] [I] [TRT] Producer version: 1.10
[12/14/2023-17:13:59] [I] [TRT] Domain:           
[12/14/2023-17:13:59] [I] [TRT] Model version:    0
[12/14/2023-17:13:59] [I] [TRT] Doc string:       
[12/14/2023-17:13:59] [I] [TRT] ----------------------------------------------------------------
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::fMHA_V2 version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::fMHCA version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::GroupNorm version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::LayerNorm version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ModulatedDeformConv2d version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::SeqLen2Spatial version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::SplitGeLU version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::Split version 1
[12/14/2023-17:13:59] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[12/14/2023-17:13:59] [V] [TRT] Adding network input: camera with dtype: float32, dimensions: (1, 80, 180, 180)
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: camera for ONNX tensor: camera
[12/14/2023-17:13:59] [V] [TRT] Adding network input: lidar with dtype: float32, dimensions: (1, 256, 180, 180)
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: lidar for ONNX tensor: lidar
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.fuser.0.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.fuser.0.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.0.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.0.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.3.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.3.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.6.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.6.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.9.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.9.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.12.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.12.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.15.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.0.15.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.0.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.3.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.3.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.6.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.6.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.9.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.9.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.12.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.12.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.15.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.backbone.blocks.1.15.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.0.0.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.0.0.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.1.1.weight
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.1.1.bias
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.1.1.running_mean
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: parent.decoder.neck.deblocks.1.1.running_var
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 611
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 612
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 613
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 614
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 615
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 616
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 617
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 618
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 619
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 620
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 621
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 622
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 623
[12/14/2023-17:13:59] [V] [TRT] Importing initializer: 624
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Concat_0 [Concat]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: camera
[12/14/2023-17:13:59] [V] [TRT] Searching for input: lidar
[12/14/2023-17:13:59] [V] [TRT] Concat_0 [Concat] inputs: [camera -> (1, 80, 180, 180)[FLOAT]], [lidar -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Concat_0 for ONNX node: Concat_0
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 424 for ONNX tensor: 424
[12/14/2023-17:13:59] [V] [TRT] Concat_0 [Concat] outputs: [424 -> (1, 336, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_1 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_1 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_1 [Constant] outputs: [425 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_2 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_2 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_2 [Constant] outputs: [426 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_3 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 424
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 425
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 426
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_3 [QuantizeLinear] inputs: [424 -> (1, 336, 180, 180)[FLOAT]], [425 -> ()[FLOAT]], [426 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 425 for ONNX node: 425
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 426 for ONNX node: 426
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 427 for ONNX tensor: 427
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_3 [QuantizeLinear] outputs: [427 -> (1, 336, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_4 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_4 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_4 [Constant] outputs: [428 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_5 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_5 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_5 [Constant] outputs: [429 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_6 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 427
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 428
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 429
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_6 [DequantizeLinear] inputs: [427 -> (1, 336, 180, 180)[FLOAT]], [428 -> ()[FLOAT]], [429 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 428 for ONNX node: 428
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 429 for ONNX node: 429
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 430 for ONNX tensor: 430
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_6 [DequantizeLinear] outputs: [430 -> (1, 336, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_7 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_7 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_7 [Constant] outputs: [431 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_8 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.fuser.0.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 431
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 611
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_8 [QuantizeLinear] inputs: [parent.fuser.0.weight -> (256, 336, 3, 3)[FLOAT]], [431 -> (256)[FLOAT]], [611 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.fuser.0.weight for ONNX node: parent.fuser.0.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 431 for ONNX node: 431
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 611 for ONNX node: 611
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 434 for ONNX tensor: 434
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_8 [QuantizeLinear] outputs: [434 -> (256, 336, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_9 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 434
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 431
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 611
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_9 [DequantizeLinear] inputs: [434 -> (256, 336, 3, 3)[FLOAT]], [431 -> (256)[FLOAT]], [611 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 435 for ONNX tensor: 435
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_9 [DequantizeLinear] outputs: [435 -> (256, 336, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_10 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 430
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 435
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.fuser.0.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_10 [Conv] inputs: [430 -> (1, 336, 180, 180)[FLOAT]], [435 -> (256, 336, 3, 3)[FLOAT]], [parent.fuser.0.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_10 for ONNX node: Conv_10
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 436 for ONNX tensor: 436
[12/14/2023-17:13:59] [V] [TRT] Conv_10 [Conv] outputs: [436 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_11 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 436
[12/14/2023-17:13:59] [V] [TRT] Relu_11 [Relu] inputs: [436 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_11 for ONNX node: Relu_11
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 437 for ONNX tensor: 437
[12/14/2023-17:13:59] [V] [TRT] Relu_11 [Relu] outputs: [437 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_12 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_12 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_12 [Constant] outputs: [438 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_13 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_13 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_13 [Constant] outputs: [439 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_14 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 437
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 438
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 439
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_14 [QuantizeLinear] inputs: [437 -> (1, 256, 180, 180)[FLOAT]], [438 -> ()[FLOAT]], [439 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 438 for ONNX node: 438
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 439 for ONNX node: 439
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 440 for ONNX tensor: 440
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_14 [QuantizeLinear] outputs: [440 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_15 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_15 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_15 [Constant] outputs: [441 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_16 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_16 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_16 [Constant] outputs: [442 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_17 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 440
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 441
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 442
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_17 [DequantizeLinear] inputs: [440 -> (1, 256, 180, 180)[FLOAT]], [441 -> ()[FLOAT]], [442 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 441 for ONNX node: 441
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 442 for ONNX node: 442
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 443 for ONNX tensor: 443
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_17 [DequantizeLinear] outputs: [443 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_18 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_18 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_18 [Constant] outputs: [444 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_19 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.0.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 444
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 612
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_19 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.0.weight -> (128, 256, 3, 3)[FLOAT]], [444 -> (128)[FLOAT]], [612 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.0.weight for ONNX node: parent.decoder.backbone.blocks.0.0.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 444 for ONNX node: 444
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 612 for ONNX node: 612
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 447 for ONNX tensor: 447
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_19 [QuantizeLinear] outputs: [447 -> (128, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_20 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 447
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 444
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 612
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_20 [DequantizeLinear] inputs: [447 -> (128, 256, 3, 3)[FLOAT]], [444 -> (128)[FLOAT]], [612 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 448 for ONNX tensor: 448
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_20 [DequantizeLinear] outputs: [448 -> (128, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_21 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 443
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 448
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.0.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_21 [Conv] inputs: [443 -> (1, 256, 180, 180)[FLOAT]], [448 -> (128, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.0.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_21 for ONNX node: Conv_21
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 449 for ONNX tensor: 449
[12/14/2023-17:13:59] [V] [TRT] Conv_21 [Conv] outputs: [449 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_22 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 449
[12/14/2023-17:13:59] [V] [TRT] Relu_22 [Relu] inputs: [449 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_22 for ONNX node: Relu_22
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 450 for ONNX tensor: 450
[12/14/2023-17:13:59] [V] [TRT] Relu_22 [Relu] outputs: [450 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_23 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_23 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_23 [Constant] outputs: [451 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_24 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_24 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_24 [Constant] outputs: [452 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_25 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 450
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 451
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 452
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_25 [QuantizeLinear] inputs: [450 -> (1, 128, 180, 180)[FLOAT]], [451 -> ()[FLOAT]], [452 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 451 for ONNX node: 451
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 452 for ONNX node: 452
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 453 for ONNX tensor: 453
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_25 [QuantizeLinear] outputs: [453 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_26 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_26 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_26 [Constant] outputs: [454 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_27 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_27 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_27 [Constant] outputs: [455 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_28 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 453
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 454
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 455
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_28 [DequantizeLinear] inputs: [453 -> (1, 128, 180, 180)[FLOAT]], [454 -> ()[FLOAT]], [455 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 454 for ONNX node: 454
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 455 for ONNX node: 455
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 456 for ONNX tensor: 456
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_28 [DequantizeLinear] outputs: [456 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_29 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_29 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_29 [Constant] outputs: [457 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_30 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.3.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 457
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 613
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_30 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.3.weight -> (128, 128, 3, 3)[FLOAT]], [457 -> (128)[FLOAT]], [613 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.3.weight for ONNX node: parent.decoder.backbone.blocks.0.3.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 457 for ONNX node: 457
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 613 for ONNX node: 613
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 460 for ONNX tensor: 460
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_30 [QuantizeLinear] outputs: [460 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_31 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 460
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 457
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 613
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_31 [DequantizeLinear] inputs: [460 -> (128, 128, 3, 3)[FLOAT]], [457 -> (128)[FLOAT]], [613 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 461 for ONNX tensor: 461
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_31 [DequantizeLinear] outputs: [461 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_32 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 456
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 461
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.3.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_32 [Conv] inputs: [456 -> (1, 128, 180, 180)[FLOAT]], [461 -> (128, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.3.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_32 for ONNX node: Conv_32
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 462 for ONNX tensor: 462
[12/14/2023-17:13:59] [V] [TRT] Conv_32 [Conv] outputs: [462 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_33 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 462
[12/14/2023-17:13:59] [V] [TRT] Relu_33 [Relu] inputs: [462 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_33 for ONNX node: Relu_33
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 463 for ONNX tensor: 463
[12/14/2023-17:13:59] [V] [TRT] Relu_33 [Relu] outputs: [463 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_34 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_34 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_34 [Constant] outputs: [464 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_35 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_35 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_35 [Constant] outputs: [465 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_36 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 463
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 464
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 465
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_36 [QuantizeLinear] inputs: [463 -> (1, 128, 180, 180)[FLOAT]], [464 -> ()[FLOAT]], [465 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 464 for ONNX node: 464
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 465 for ONNX node: 465
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 466 for ONNX tensor: 466
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_36 [QuantizeLinear] outputs: [466 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_37 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_37 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_37 [Constant] outputs: [467 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_38 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_38 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_38 [Constant] outputs: [468 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_39 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 466
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 467
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 468
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_39 [DequantizeLinear] inputs: [466 -> (1, 128, 180, 180)[FLOAT]], [467 -> ()[FLOAT]], [468 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 467 for ONNX node: 467
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 468 for ONNX node: 468
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 469 for ONNX tensor: 469
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_39 [DequantizeLinear] outputs: [469 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_40 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_40 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_40 [Constant] outputs: [470 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_41 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.6.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 470
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 614
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_41 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.6.weight -> (128, 128, 3, 3)[FLOAT]], [470 -> (128)[FLOAT]], [614 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.6.weight for ONNX node: parent.decoder.backbone.blocks.0.6.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 470 for ONNX node: 470
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 614 for ONNX node: 614
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 473 for ONNX tensor: 473
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_41 [QuantizeLinear] outputs: [473 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_42 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 473
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 470
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 614
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_42 [DequantizeLinear] inputs: [473 -> (128, 128, 3, 3)[FLOAT]], [470 -> (128)[FLOAT]], [614 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 474 for ONNX tensor: 474
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_42 [DequantizeLinear] outputs: [474 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_43 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 469
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 474
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.6.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_43 [Conv] inputs: [469 -> (1, 128, 180, 180)[FLOAT]], [474 -> (128, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.6.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_43 for ONNX node: Conv_43
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 475 for ONNX tensor: 475
[12/14/2023-17:13:59] [V] [TRT] Conv_43 [Conv] outputs: [475 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_44 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 475
[12/14/2023-17:13:59] [V] [TRT] Relu_44 [Relu] inputs: [475 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_44 for ONNX node: Relu_44
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 476 for ONNX tensor: 476
[12/14/2023-17:13:59] [V] [TRT] Relu_44 [Relu] outputs: [476 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_45 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_45 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_45 [Constant] outputs: [477 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_46 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_46 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_46 [Constant] outputs: [478 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_47 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 476
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 477
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 478
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_47 [QuantizeLinear] inputs: [476 -> (1, 128, 180, 180)[FLOAT]], [477 -> ()[FLOAT]], [478 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 477 for ONNX node: 477
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 478 for ONNX node: 478
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 479 for ONNX tensor: 479
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_47 [QuantizeLinear] outputs: [479 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_48 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_48 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_48 [Constant] outputs: [480 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_49 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_49 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_49 [Constant] outputs: [481 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_50 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 479
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 480
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 481
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_50 [DequantizeLinear] inputs: [479 -> (1, 128, 180, 180)[FLOAT]], [480 -> ()[FLOAT]], [481 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 480 for ONNX node: 480
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 481 for ONNX node: 481
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 482 for ONNX tensor: 482
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_50 [DequantizeLinear] outputs: [482 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_51 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_51 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_51 [Constant] outputs: [483 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_52 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.9.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 483
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 615
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_52 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.9.weight -> (128, 128, 3, 3)[FLOAT]], [483 -> (128)[FLOAT]], [615 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.9.weight for ONNX node: parent.decoder.backbone.blocks.0.9.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 483 for ONNX node: 483
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 615 for ONNX node: 615
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 486 for ONNX tensor: 486
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_52 [QuantizeLinear] outputs: [486 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_53 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 486
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 483
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 615
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_53 [DequantizeLinear] inputs: [486 -> (128, 128, 3, 3)[FLOAT]], [483 -> (128)[FLOAT]], [615 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 487 for ONNX tensor: 487
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_53 [DequantizeLinear] outputs: [487 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_54 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 482
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 487
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.9.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_54 [Conv] inputs: [482 -> (1, 128, 180, 180)[FLOAT]], [487 -> (128, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.9.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_54 for ONNX node: Conv_54
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 488 for ONNX tensor: 488
[12/14/2023-17:13:59] [V] [TRT] Conv_54 [Conv] outputs: [488 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_55 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 488
[12/14/2023-17:13:59] [V] [TRT] Relu_55 [Relu] inputs: [488 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_55 for ONNX node: Relu_55
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 489 for ONNX tensor: 489
[12/14/2023-17:13:59] [V] [TRT] Relu_55 [Relu] outputs: [489 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_56 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_56 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_56 [Constant] outputs: [490 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_57 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_57 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_57 [Constant] outputs: [491 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_58 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 489
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 490
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 491
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_58 [QuantizeLinear] inputs: [489 -> (1, 128, 180, 180)[FLOAT]], [490 -> ()[FLOAT]], [491 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 490 for ONNX node: 490
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 491 for ONNX node: 491
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 492 for ONNX tensor: 492
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_58 [QuantizeLinear] outputs: [492 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_59 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_59 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_59 [Constant] outputs: [493 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_60 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_60 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_60 [Constant] outputs: [494 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_61 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 492
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 493
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 494
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_61 [DequantizeLinear] inputs: [492 -> (1, 128, 180, 180)[FLOAT]], [493 -> ()[FLOAT]], [494 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 493 for ONNX node: 493
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 494 for ONNX node: 494
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 495 for ONNX tensor: 495
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_61 [DequantizeLinear] outputs: [495 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_62 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_62 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_62 [Constant] outputs: [496 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_63 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.12.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 496
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 616
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_63 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.12.weight -> (128, 128, 3, 3)[FLOAT]], [496 -> (128)[FLOAT]], [616 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.12.weight for ONNX node: parent.decoder.backbone.blocks.0.12.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 496 for ONNX node: 496
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 616 for ONNX node: 616
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 499 for ONNX tensor: 499
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_63 [QuantizeLinear] outputs: [499 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_64 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 499
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 496
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 616
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_64 [DequantizeLinear] inputs: [499 -> (128, 128, 3, 3)[FLOAT]], [496 -> (128)[FLOAT]], [616 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 500 for ONNX tensor: 500
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_64 [DequantizeLinear] outputs: [500 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_65 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 495
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 500
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.12.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_65 [Conv] inputs: [495 -> (1, 128, 180, 180)[FLOAT]], [500 -> (128, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.12.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_65 for ONNX node: Conv_65
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 501 for ONNX tensor: 501
[12/14/2023-17:13:59] [V] [TRT] Conv_65 [Conv] outputs: [501 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_66 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 501
[12/14/2023-17:13:59] [V] [TRT] Relu_66 [Relu] inputs: [501 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_66 for ONNX node: Relu_66
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 502 for ONNX tensor: 502
[12/14/2023-17:13:59] [V] [TRT] Relu_66 [Relu] outputs: [502 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_67 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_67 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_67 [Constant] outputs: [503 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_68 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_68 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_68 [Constant] outputs: [504 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_69 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 502
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 503
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 504
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_69 [QuantizeLinear] inputs: [502 -> (1, 128, 180, 180)[FLOAT]], [503 -> ()[FLOAT]], [504 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 503 for ONNX node: 503
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 504 for ONNX node: 504
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 505 for ONNX tensor: 505
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_69 [QuantizeLinear] outputs: [505 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_70 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_70 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_70 [Constant] outputs: [506 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_71 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_71 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_71 [Constant] outputs: [507 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_72 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 505
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 506
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 507
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_72 [DequantizeLinear] inputs: [505 -> (1, 128, 180, 180)[FLOAT]], [506 -> ()[FLOAT]], [507 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 506 for ONNX node: 506
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 507 for ONNX node: 507
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 508 for ONNX tensor: 508
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_72 [DequantizeLinear] outputs: [508 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_73 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_73 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_73 [Constant] outputs: [509 -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_74 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.15.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 509
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 617
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_74 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.0.15.weight -> (128, 128, 3, 3)[FLOAT]], [509 -> (128)[FLOAT]], [617 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.0.15.weight for ONNX node: parent.decoder.backbone.blocks.0.15.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 509 for ONNX node: 509
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 617 for ONNX node: 617
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 512 for ONNX tensor: 512
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_74 [QuantizeLinear] outputs: [512 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_75 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 512
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 509
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 617
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_75 [DequantizeLinear] inputs: [512 -> (128, 128, 3, 3)[FLOAT]], [509 -> (128)[FLOAT]], [617 -> (128)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 513 for ONNX tensor: 513
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_75 [DequantizeLinear] outputs: [513 -> (128, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_76 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 508
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 513
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.0.15.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_76 [Conv] inputs: [508 -> (1, 128, 180, 180)[FLOAT]], [513 -> (128, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.0.15.bias -> (128)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_76 for ONNX node: Conv_76
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 514 for ONNX tensor: 514
[12/14/2023-17:13:59] [V] [TRT] Conv_76 [Conv] outputs: [514 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_77 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 514
[12/14/2023-17:13:59] [V] [TRT] Relu_77 [Relu] inputs: [514 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_77 for ONNX node: Relu_77
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 515 for ONNX tensor: 515
[12/14/2023-17:13:59] [V] [TRT] Relu_77 [Relu] outputs: [515 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_78 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_78 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_78 [Constant] outputs: [516 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_79 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_79 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_79 [Constant] outputs: [517 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_80 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 515
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 516
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 517
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_80 [QuantizeLinear] inputs: [515 -> (1, 128, 180, 180)[FLOAT]], [516 -> ()[FLOAT]], [517 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 516 for ONNX node: 516
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 517 for ONNX node: 517
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 518 for ONNX tensor: 518
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_80 [QuantizeLinear] outputs: [518 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_81 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_81 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_81 [Constant] outputs: [519 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_82 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_82 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_82 [Constant] outputs: [520 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_83 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 518
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 519
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 520
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_83 [DequantizeLinear] inputs: [518 -> (1, 128, 180, 180)[FLOAT]], [519 -> ()[FLOAT]], [520 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 519 for ONNX node: 519
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 520 for ONNX node: 520
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 521 for ONNX tensor: 521
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_83 [DequantizeLinear] outputs: [521 -> (1, 128, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_84 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_84 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_84 [Constant] outputs: [522 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_85 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 522
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 618
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_85 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.0.weight -> (256, 128, 3, 3)[FLOAT]], [522 -> (256)[FLOAT]], [618 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.0.weight for ONNX node: parent.decoder.backbone.blocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 522 for ONNX node: 522
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 618 for ONNX node: 618
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 525 for ONNX tensor: 525
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_85 [QuantizeLinear] outputs: [525 -> (256, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_86 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 525
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 522
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 618
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_86 [DequantizeLinear] inputs: [525 -> (256, 128, 3, 3)[FLOAT]], [522 -> (256)[FLOAT]], [618 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 526 for ONNX tensor: 526
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_86 [DequantizeLinear] outputs: [526 -> (256, 128, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_87 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 521
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 526
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.0.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_87 [Conv] inputs: [521 -> (1, 128, 180, 180)[FLOAT]], [526 -> (256, 128, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.0.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_87 for ONNX node: Conv_87
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 527 for ONNX tensor: 527
[12/14/2023-17:13:59] [V] [TRT] Conv_87 [Conv] outputs: [527 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_88 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 527
[12/14/2023-17:13:59] [V] [TRT] Relu_88 [Relu] inputs: [527 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_88 for ONNX node: Relu_88
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 528 for ONNX tensor: 528
[12/14/2023-17:13:59] [V] [TRT] Relu_88 [Relu] outputs: [528 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_89 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_89 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_89 [Constant] outputs: [529 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_90 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_90 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_90 [Constant] outputs: [530 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_91 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 528
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 529
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 530
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_91 [QuantizeLinear] inputs: [528 -> (1, 256, 90, 90)[FLOAT]], [529 -> ()[FLOAT]], [530 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 529 for ONNX node: 529
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 530 for ONNX node: 530
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 531 for ONNX tensor: 531
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_91 [QuantizeLinear] outputs: [531 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_92 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_92 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_92 [Constant] outputs: [532 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_93 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_93 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_93 [Constant] outputs: [533 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_94 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 531
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 532
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 533
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_94 [DequantizeLinear] inputs: [531 -> (1, 256, 90, 90)[FLOAT]], [532 -> ()[FLOAT]], [533 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 532 for ONNX node: 532
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 533 for ONNX node: 533
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 534 for ONNX tensor: 534
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_94 [DequantizeLinear] outputs: [534 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_95 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_95 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_95 [Constant] outputs: [535 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_96 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.3.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 535
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 619
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_96 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.3.weight -> (256, 256, 3, 3)[FLOAT]], [535 -> (256)[FLOAT]], [619 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.3.weight for ONNX node: parent.decoder.backbone.blocks.1.3.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 535 for ONNX node: 535
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 619 for ONNX node: 619
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 538 for ONNX tensor: 538
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_96 [QuantizeLinear] outputs: [538 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_97 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 538
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 535
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 619
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_97 [DequantizeLinear] inputs: [538 -> (256, 256, 3, 3)[FLOAT]], [535 -> (256)[FLOAT]], [619 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 539 for ONNX tensor: 539
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_97 [DequantizeLinear] outputs: [539 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_98 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 534
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 539
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.3.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_98 [Conv] inputs: [534 -> (1, 256, 90, 90)[FLOAT]], [539 -> (256, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.3.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_98 for ONNX node: Conv_98
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 540 for ONNX tensor: 540
[12/14/2023-17:13:59] [V] [TRT] Conv_98 [Conv] outputs: [540 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_99 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 540
[12/14/2023-17:13:59] [V] [TRT] Relu_99 [Relu] inputs: [540 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_99 for ONNX node: Relu_99
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 541 for ONNX tensor: 541
[12/14/2023-17:13:59] [V] [TRT] Relu_99 [Relu] outputs: [541 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_100 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_100 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_100 [Constant] outputs: [542 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_101 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_101 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_101 [Constant] outputs: [543 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_102 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 541
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 542
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 543
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_102 [QuantizeLinear] inputs: [541 -> (1, 256, 90, 90)[FLOAT]], [542 -> ()[FLOAT]], [543 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 542 for ONNX node: 542
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 543 for ONNX node: 543
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 544 for ONNX tensor: 544
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_102 [QuantizeLinear] outputs: [544 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_103 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_103 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_103 [Constant] outputs: [545 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_104 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_104 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_104 [Constant] outputs: [546 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_105 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 544
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 545
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 546
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_105 [DequantizeLinear] inputs: [544 -> (1, 256, 90, 90)[FLOAT]], [545 -> ()[FLOAT]], [546 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 545 for ONNX node: 545
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 546 for ONNX node: 546
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 547 for ONNX tensor: 547
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_105 [DequantizeLinear] outputs: [547 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_106 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_106 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_106 [Constant] outputs: [548 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_107 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.6.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 548
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 620
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_107 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.6.weight -> (256, 256, 3, 3)[FLOAT]], [548 -> (256)[FLOAT]], [620 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.6.weight for ONNX node: parent.decoder.backbone.blocks.1.6.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 548 for ONNX node: 548
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 620 for ONNX node: 620
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 551 for ONNX tensor: 551
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_107 [QuantizeLinear] outputs: [551 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_108 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 551
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 548
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 620
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_108 [DequantizeLinear] inputs: [551 -> (256, 256, 3, 3)[FLOAT]], [548 -> (256)[FLOAT]], [620 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 552 for ONNX tensor: 552
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_108 [DequantizeLinear] outputs: [552 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_109 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 547
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 552
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.6.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_109 [Conv] inputs: [547 -> (1, 256, 90, 90)[FLOAT]], [552 -> (256, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.6.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_109 for ONNX node: Conv_109
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 553 for ONNX tensor: 553
[12/14/2023-17:13:59] [V] [TRT] Conv_109 [Conv] outputs: [553 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_110 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 553
[12/14/2023-17:13:59] [V] [TRT] Relu_110 [Relu] inputs: [553 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_110 for ONNX node: Relu_110
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 554 for ONNX tensor: 554
[12/14/2023-17:13:59] [V] [TRT] Relu_110 [Relu] outputs: [554 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_111 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_111 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_111 [Constant] outputs: [555 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_112 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_112 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_112 [Constant] outputs: [556 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_113 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 554
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 555
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 556
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_113 [QuantizeLinear] inputs: [554 -> (1, 256, 90, 90)[FLOAT]], [555 -> ()[FLOAT]], [556 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 555 for ONNX node: 555
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 556 for ONNX node: 556
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 557 for ONNX tensor: 557
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_113 [QuantizeLinear] outputs: [557 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_114 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_114 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_114 [Constant] outputs: [558 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_115 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_115 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_115 [Constant] outputs: [559 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_116 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 557
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 558
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 559
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_116 [DequantizeLinear] inputs: [557 -> (1, 256, 90, 90)[FLOAT]], [558 -> ()[FLOAT]], [559 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 558 for ONNX node: 558
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 559 for ONNX node: 559
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 560 for ONNX tensor: 560
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_116 [DequantizeLinear] outputs: [560 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_117 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_117 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_117 [Constant] outputs: [561 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_118 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.9.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 561
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 621
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_118 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.9.weight -> (256, 256, 3, 3)[FLOAT]], [561 -> (256)[FLOAT]], [621 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.9.weight for ONNX node: parent.decoder.backbone.blocks.1.9.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 561 for ONNX node: 561
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 621 for ONNX node: 621
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 564 for ONNX tensor: 564
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_118 [QuantizeLinear] outputs: [564 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_119 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 564
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 561
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 621
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_119 [DequantizeLinear] inputs: [564 -> (256, 256, 3, 3)[FLOAT]], [561 -> (256)[FLOAT]], [621 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 565 for ONNX tensor: 565
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_119 [DequantizeLinear] outputs: [565 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_120 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 560
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 565
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.9.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_120 [Conv] inputs: [560 -> (1, 256, 90, 90)[FLOAT]], [565 -> (256, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.9.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_120 for ONNX node: Conv_120
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 566 for ONNX tensor: 566
[12/14/2023-17:13:59] [V] [TRT] Conv_120 [Conv] outputs: [566 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_121 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 566
[12/14/2023-17:13:59] [V] [TRT] Relu_121 [Relu] inputs: [566 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_121 for ONNX node: Relu_121
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 567 for ONNX tensor: 567
[12/14/2023-17:13:59] [V] [TRT] Relu_121 [Relu] outputs: [567 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_122 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_122 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_122 [Constant] outputs: [568 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_123 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_123 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_123 [Constant] outputs: [569 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_124 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 567
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 568
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 569
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_124 [QuantizeLinear] inputs: [567 -> (1, 256, 90, 90)[FLOAT]], [568 -> ()[FLOAT]], [569 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 568 for ONNX node: 568
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 569 for ONNX node: 569
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 570 for ONNX tensor: 570
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_124 [QuantizeLinear] outputs: [570 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_125 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_125 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_125 [Constant] outputs: [571 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_126 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_126 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_126 [Constant] outputs: [572 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_127 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 570
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 571
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 572
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_127 [DequantizeLinear] inputs: [570 -> (1, 256, 90, 90)[FLOAT]], [571 -> ()[FLOAT]], [572 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 571 for ONNX node: 571
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 572 for ONNX node: 572
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 573 for ONNX tensor: 573
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_127 [DequantizeLinear] outputs: [573 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_128 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_128 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_128 [Constant] outputs: [574 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_129 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.12.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 574
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 622
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_129 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.12.weight -> (256, 256, 3, 3)[FLOAT]], [574 -> (256)[FLOAT]], [622 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.12.weight for ONNX node: parent.decoder.backbone.blocks.1.12.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 574 for ONNX node: 574
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 622 for ONNX node: 622
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 577 for ONNX tensor: 577
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_129 [QuantizeLinear] outputs: [577 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_130 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 577
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 574
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 622
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_130 [DequantizeLinear] inputs: [577 -> (256, 256, 3, 3)[FLOAT]], [574 -> (256)[FLOAT]], [622 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 578 for ONNX tensor: 578
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_130 [DequantizeLinear] outputs: [578 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_131 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 573
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 578
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.12.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_131 [Conv] inputs: [573 -> (1, 256, 90, 90)[FLOAT]], [578 -> (256, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.12.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_131 for ONNX node: Conv_131
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 579 for ONNX tensor: 579
[12/14/2023-17:13:59] [V] [TRT] Conv_131 [Conv] outputs: [579 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_132 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 579
[12/14/2023-17:13:59] [V] [TRT] Relu_132 [Relu] inputs: [579 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_132 for ONNX node: Relu_132
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 580 for ONNX tensor: 580
[12/14/2023-17:13:59] [V] [TRT] Relu_132 [Relu] outputs: [580 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_133 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_133 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_133 [Constant] outputs: [581 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_134 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_134 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_134 [Constant] outputs: [582 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_135 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 580
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 581
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 582
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_135 [QuantizeLinear] inputs: [580 -> (1, 256, 90, 90)[FLOAT]], [581 -> ()[FLOAT]], [582 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 581 for ONNX node: 581
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 582 for ONNX node: 582
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 583 for ONNX tensor: 583
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_135 [QuantizeLinear] outputs: [583 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_136 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_136 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_136 [Constant] outputs: [584 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_137 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_137 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_137 [Constant] outputs: [585 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_138 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 583
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 584
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 585
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_138 [DequantizeLinear] inputs: [583 -> (1, 256, 90, 90)[FLOAT]], [584 -> ()[FLOAT]], [585 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 584 for ONNX node: 584
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 585 for ONNX node: 585
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 586 for ONNX tensor: 586
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_138 [DequantizeLinear] outputs: [586 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_139 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_139 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_139 [Constant] outputs: [587 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_140 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.15.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 587
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 623
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_140 [QuantizeLinear] inputs: [parent.decoder.backbone.blocks.1.15.weight -> (256, 256, 3, 3)[FLOAT]], [587 -> (256)[FLOAT]], [623 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.backbone.blocks.1.15.weight for ONNX node: parent.decoder.backbone.blocks.1.15.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 587 for ONNX node: 587
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 623 for ONNX node: 623
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 590 for ONNX tensor: 590
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_140 [QuantizeLinear] outputs: [590 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_141 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 590
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 587
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 623
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_141 [DequantizeLinear] inputs: [590 -> (256, 256, 3, 3)[FLOAT]], [587 -> (256)[FLOAT]], [623 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 591 for ONNX tensor: 591
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_141 [DequantizeLinear] outputs: [591 -> (256, 256, 3, 3)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_142 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 586
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 591
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.backbone.blocks.1.15.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_142 [Conv] inputs: [586 -> (1, 256, 90, 90)[FLOAT]], [591 -> (256, 256, 3, 3)[FLOAT]], [parent.decoder.backbone.blocks.1.15.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_142 for ONNX node: Conv_142
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 592 for ONNX tensor: 592
[12/14/2023-17:13:59] [V] [TRT] Conv_142 [Conv] outputs: [592 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_143 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 592
[12/14/2023-17:13:59] [V] [TRT] Relu_143 [Relu] inputs: [592 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_143 for ONNX node: Relu_143
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 593 for ONNX tensor: 593
[12/14/2023-17:13:59] [V] [TRT] Relu_143 [Relu] outputs: [593 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Conv_144 [Conv]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 515
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.0.0.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.0.0.bias
[12/14/2023-17:13:59] [V] [TRT] Conv_144 [Conv] inputs: [515 -> (1, 128, 180, 180)[FLOAT]], [parent.decoder.neck.deblocks.0.0.weight -> (256, 128, 1, 1)[FLOAT]], [parent.decoder.neck.deblocks.0.0.bias -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Conv_144 for ONNX node: Conv_144
[12/14/2023-17:13:59] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[12/14/2023-17:13:59] [V] [TRT] Convolution output dimensions: (1, 256, 180, 180)
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 594 for ONNX tensor: 594
[12/14/2023-17:13:59] [V] [TRT] Conv_144 [Conv] outputs: [594 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_145 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 594
[12/14/2023-17:13:59] [V] [TRT] Relu_145 [Relu] inputs: [594 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_145 for ONNX node: Relu_145
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 595 for ONNX tensor: 595
[12/14/2023-17:13:59] [V] [TRT] Relu_145 [Relu] outputs: [595 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_146 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_146 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_146 [Constant] outputs: [596 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_147 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_147 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_147 [Constant] outputs: [597 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_148 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 593
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 596
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 597
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_148 [QuantizeLinear] inputs: [593 -> (1, 256, 90, 90)[FLOAT]], [596 -> ()[FLOAT]], [597 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 596 for ONNX node: 596
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 597 for ONNX node: 597
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 598 for ONNX tensor: 598
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_148 [QuantizeLinear] outputs: [598 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_149 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_149 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_149 [Constant] outputs: [599 -> ()[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_150 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_150 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_150 [Constant] outputs: [600 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_151 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 598
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 599
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 600
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_151 [DequantizeLinear] inputs: [598 -> (1, 256, 90, 90)[FLOAT]], [599 -> ()[FLOAT]], [600 -> ()[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 599 for ONNX node: 599
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 600 for ONNX node: 600
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 601 for ONNX tensor: 601
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_151 [DequantizeLinear] outputs: [601 -> (1, 256, 90, 90)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Constant_152 [Constant]
[12/14/2023-17:13:59] [V] [TRT] Constant_152 [Constant] inputs: 
[12/14/2023-17:13:59] [V] [TRT] Constant_152 [Constant] outputs: [602 -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: QuantizeLinear_153 [QuantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 602
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 624
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_153 [QuantizeLinear] inputs: [parent.decoder.neck.deblocks.1.0.weight -> (256, 256, 2, 2)[FLOAT]], [602 -> (256)[FLOAT]], [624 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: parent.decoder.neck.deblocks.1.0.weight for ONNX node: parent.decoder.neck.deblocks.1.0.weight
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 602 for ONNX node: 602
[12/14/2023-17:13:59] [V] [TRT] Registering layer: 624 for ONNX node: 624
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 605 for ONNX tensor: 605
[12/14/2023-17:13:59] [V] [TRT] QuantizeLinear_153 [QuantizeLinear] outputs: [605 -> (256, 256, 2, 2)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: DequantizeLinear_154 [DequantizeLinear]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 605
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 602
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 624
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_154 [DequantizeLinear] inputs: [605 -> (256, 256, 2, 2)[FLOAT]], [602 -> (256)[FLOAT]], [624 -> (256)[INT8]], 
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 606 for ONNX tensor: 606
[12/14/2023-17:13:59] [V] [TRT] DequantizeLinear_154 [DequantizeLinear] outputs: [606 -> (256, 256, 2, 2)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: ConvTranspose_155 [ConvTranspose]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 601
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 606
[12/14/2023-17:13:59] [V] [TRT] ConvTranspose_155 [ConvTranspose] inputs: [601 -> (1, 256, 90, 90)[FLOAT]], [606 -> (256, 256, 2, 2)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[12/14/2023-17:13:59] [V] [TRT] Running deconvolution with: 
Padding mode: NOTSET
Pre-padding: (0, 0)
Post-padding: (0, 0)
[12/14/2023-17:13:59] [V] [TRT] Registering layer: ConvTranspose_155 for ONNX node: ConvTranspose_155
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 607 for ONNX tensor: 607
[12/14/2023-17:13:59] [V] [TRT] ConvTranspose_155 [ConvTranspose] outputs: [607 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: BatchNormalization_156 [BatchNormalization]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 607
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.1.1.weight
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.1.1.bias
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.1.1.running_mean
[12/14/2023-17:13:59] [V] [TRT] Searching for input: parent.decoder.neck.deblocks.1.1.running_var
[12/14/2023-17:13:59] [V] [TRT] BatchNormalization_156 [BatchNormalization] inputs: [607 -> (1, 256, 180, 180)[FLOAT]], [parent.decoder.neck.deblocks.1.1.weight -> (256)[FLOAT]], [parent.decoder.neck.deblocks.1.1.bias -> (256)[FLOAT]], [parent.decoder.neck.deblocks.1.1.running_mean -> (256)[FLOAT]], [parent.decoder.neck.deblocks.1.1.running_var -> (256)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: BatchNormalization_156 for ONNX node: BatchNormalization_156
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 608 for ONNX tensor: 608
[12/14/2023-17:13:59] [V] [TRT] BatchNormalization_156 [BatchNormalization] outputs: [608 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Relu_157 [Relu]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 608
[12/14/2023-17:13:59] [V] [TRT] Relu_157 [Relu] inputs: [608 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Relu_157 for ONNX node: Relu_157
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: 609 for ONNX tensor: 609
[12/14/2023-17:13:59] [V] [TRT] Relu_157 [Relu] outputs: [609 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Parsing node: Concat_158 [Concat]
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 595
[12/14/2023-17:13:59] [V] [TRT] Searching for input: 609
[12/14/2023-17:13:59] [V] [TRT] Concat_158 [Concat] inputs: [595 -> (1, 256, 180, 180)[FLOAT]], [609 -> (1, 256, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Registering layer: Concat_158 for ONNX node: Concat_158
[12/14/2023-17:13:59] [V] [TRT] Registering tensor: middle_43 for ONNX tensor: middle
[12/14/2023-17:13:59] [V] [TRT] Concat_158 [Concat] outputs: [middle -> (1, 512, 180, 180)[FLOAT]], 
[12/14/2023-17:13:59] [V] [TRT] Marking middle_43 as output: middle
[12/14/2023-17:13:59] [I] Finished parsing network model. Parse time: 0.0574493
[12/14/2023-17:14:00] [W] [TRT] Calibrator won't be used in explicit precision mode. Use quantization aware training to generate network with Quantize/Dequantize nodes.
[12/14/2023-17:14:00] [V] [TRT] Original: 187 layers
[12/14/2023-17:14:00] [V] [TRT] After dead-layer removal: 187 layers
[12/14/2023-17:14:00] [V] [TRT] Graph construction completed in 0.00208979 seconds.
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_8
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_19
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_30
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_41
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_52
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_63
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_74
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_85
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_96
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_107
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_118
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_129
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_140
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_153
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_3
[12/14/2023-17:14:00] [V] [TRT] Removing 426
[12/14/2023-17:14:00] [V] [TRT] Removing 425
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_20
[12/14/2023-17:14:00] [V] [TRT] Removing 612
[12/14/2023-17:14:00] [V] [TRT] Removing 444
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_42
[12/14/2023-17:14:00] [V] [TRT] Removing 614
[12/14/2023-17:14:00] [V] [TRT] Removing 470
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_64
[12/14/2023-17:14:00] [V] [TRT] Removing 616
[12/14/2023-17:14:00] [V] [TRT] Removing 496
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_86
[12/14/2023-17:14:00] [V] [TRT] Removing 618
[12/14/2023-17:14:00] [V] [TRT] Removing 522
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_108
[12/14/2023-17:14:00] [V] [TRT] Removing 620
[12/14/2023-17:14:00] [V] [TRT] Removing 548
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_130
[12/14/2023-17:14:00] [V] [TRT] Removing 622
[12/14/2023-17:14:00] [V] [TRT] Removing 574
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_154
[12/14/2023-17:14:00] [V] [TRT] Removing 624
[12/14/2023-17:14:00] [V] [TRT] Removing 602
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_14
[12/14/2023-17:14:00] [V] [TRT] Removing 439
[12/14/2023-17:14:00] [V] [TRT] Removing 438
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_25
[12/14/2023-17:14:00] [V] [TRT] Removing 452
[12/14/2023-17:14:00] [V] [TRT] Removing 451
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_36
[12/14/2023-17:14:00] [V] [TRT] Removing 465
[12/14/2023-17:14:00] [V] [TRT] Removing 464
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_47
[12/14/2023-17:14:00] [V] [TRT] Removing 478
[12/14/2023-17:14:00] [V] [TRT] Removing 477
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_58
[12/14/2023-17:14:00] [V] [TRT] Removing 491
[12/14/2023-17:14:00] [V] [TRT] Removing 490
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_69
[12/14/2023-17:14:00] [V] [TRT] Removing 504
[12/14/2023-17:14:00] [V] [TRT] Removing 503
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_80
[12/14/2023-17:14:00] [V] [TRT] Removing 517
[12/14/2023-17:14:00] [V] [TRT] Removing 516
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_83
[12/14/2023-17:14:00] [V] [TRT] Removing 520
[12/14/2023-17:14:00] [V] [TRT] Removing 519
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_91
[12/14/2023-17:14:00] [V] [TRT] Removing 530
[12/14/2023-17:14:00] [V] [TRT] Removing 529
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_102
[12/14/2023-17:14:00] [V] [TRT] Removing 543
[12/14/2023-17:14:00] [V] [TRT] Removing 542
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_113
[12/14/2023-17:14:00] [V] [TRT] Removing 556
[12/14/2023-17:14:00] [V] [TRT] Removing 555
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_124
[12/14/2023-17:14:00] [V] [TRT] Removing 569
[12/14/2023-17:14:00] [V] [TRT] Removing 568
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_135
[12/14/2023-17:14:00] [V] [TRT] Removing 582
[12/14/2023-17:14:00] [V] [TRT] Removing 581
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_148
[12/14/2023-17:14:00] [V] [TRT] Removing 597
[12/14/2023-17:14:00] [V] [TRT] Removing 596
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_9
[12/14/2023-17:14:00] [V] [TRT] Removing 611
[12/14/2023-17:14:00] [V] [TRT] Removing 431
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_31
[12/14/2023-17:14:00] [V] [TRT] Removing 613
[12/14/2023-17:14:00] [V] [TRT] Removing 457
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_53
[12/14/2023-17:14:00] [V] [TRT] Removing 615
[12/14/2023-17:14:00] [V] [TRT] Removing 483
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_75
[12/14/2023-17:14:00] [V] [TRT] Removing 617
[12/14/2023-17:14:00] [V] [TRT] Removing 509
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_97
[12/14/2023-17:14:00] [V] [TRT] Removing 619
[12/14/2023-17:14:00] [V] [TRT] Removing 535
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_119
[12/14/2023-17:14:00] [V] [TRT] Removing 621
[12/14/2023-17:14:00] [V] [TRT] Removing 561
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_141
[12/14/2023-17:14:00] [V] [TRT] Removing 623
[12/14/2023-17:14:00] [V] [TRT] Removing 587
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_6
[12/14/2023-17:14:00] [V] [TRT] Removing 429
[12/14/2023-17:14:00] [V] [TRT] Removing 428
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_17
[12/14/2023-17:14:00] [V] [TRT] Removing 442
[12/14/2023-17:14:00] [V] [TRT] Removing 441
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_28
[12/14/2023-17:14:00] [V] [TRT] Removing 455
[12/14/2023-17:14:00] [V] [TRT] Removing 454
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_39
[12/14/2023-17:14:00] [V] [TRT] Removing 468
[12/14/2023-17:14:00] [V] [TRT] Removing 467
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_50
[12/14/2023-17:14:00] [V] [TRT] Removing 481
[12/14/2023-17:14:00] [V] [TRT] Removing 480
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_61
[12/14/2023-17:14:00] [V] [TRT] Removing 494
[12/14/2023-17:14:00] [V] [TRT] Removing 493
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_72
[12/14/2023-17:14:00] [V] [TRT] Removing 507
[12/14/2023-17:14:00] [V] [TRT] Removing 506
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_94
[12/14/2023-17:14:00] [V] [TRT] Removing 533
[12/14/2023-17:14:00] [V] [TRT] Removing 532
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_105
[12/14/2023-17:14:00] [V] [TRT] Removing 546
[12/14/2023-17:14:00] [V] [TRT] Removing 545
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_116
[12/14/2023-17:14:00] [V] [TRT] Removing 559
[12/14/2023-17:14:00] [V] [TRT] Removing 558
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_127
[12/14/2023-17:14:00] [V] [TRT] Removing 572
[12/14/2023-17:14:00] [V] [TRT] Removing 571
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_138
[12/14/2023-17:14:00] [V] [TRT] Removing 585
[12/14/2023-17:14:00] [V] [TRT] Removing 584
[12/14/2023-17:14:00] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_151
[12/14/2023-17:14:00] [V] [TRT] Removing 600
[12/14/2023-17:14:00] [V] [TRT] Removing 599
[12/14/2023-17:14:00] [V] [TRT] After Myelin optimization: 103 layers
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer forward pass - DQ motions and fusions
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer backward pass
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer quantization pass - Generate quantized ops
[12/14/2023-17:14:00] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_156
[12/14/2023-17:14:00] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_156 with Relu_157
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.fuser.0.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.fuser.0.weight with QuantizeLinear_8
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.0.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.0.weight with QuantizeLinear_19
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.3.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.3.weight with QuantizeLinear_30
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.6.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.6.weight with QuantizeLinear_41
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.9.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.9.weight with QuantizeLinear_52
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.12.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.12.weight with QuantizeLinear_63
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.0.15.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.0.15.weight with QuantizeLinear_74
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.0.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.0.weight with QuantizeLinear_85
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.3.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.3.weight with QuantizeLinear_96
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.6.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.6.weight with QuantizeLinear_107
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.9.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.9.weight with QuantizeLinear_118
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.12.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.12.weight with QuantizeLinear_129
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.backbone.blocks.1.15.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.backbone.blocks.1.15.weight with QuantizeLinear_140
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsQuantizeFusion on parent.decoder.neck.deblocks.1.0.weight
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsQuantizeFusion: Fusing parent.decoder.neck.deblocks.1.0.weight with QuantizeLinear_153
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_10
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_10 with Relu_11
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_21
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_21 with Relu_22
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_32
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_32 with Relu_33
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_43
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_43 with Relu_44
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_54
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_54 with Relu_55
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_65
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_65 with Relu_66
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_76
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_76 with Relu_77
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_144
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_144 with Relu_145
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_87
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_87 with Relu_88
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_98
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_98 with Relu_99
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_109
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_109 with Relu_110
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_120
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_120 with Relu_121
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_131
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_131 with Relu_132
[12/14/2023-17:14:00] [V] [TRT] Running: ConvReluFusion on Conv_142
[12/14/2023-17:14:00] [V] [TRT] ConvReluFusion: Fusing Conv_142 with Relu_143
[12/14/2023-17:14:00] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_0
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_10 + Relu_11
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_14 into Conv_10 + Relu_11
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_6 and DequantizeLinear_9) into Conv_10 + Relu_11
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_14
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_6
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_9
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_21 + Relu_22
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_25 into Conv_21 + Relu_22
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_17 and DequantizeLinear_20) into Conv_21 + Relu_22
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_25
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_17
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_20
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_32 + Relu_33
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_36 into Conv_32 + Relu_33
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_28 and DequantizeLinear_31) into Conv_32 + Relu_33
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_36
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_28
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_31
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_43 + Relu_44
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_47 into Conv_43 + Relu_44
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_39 and DequantizeLinear_42) into Conv_43 + Relu_44
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_47
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_39
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_42
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_54 + Relu_55
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_58 into Conv_54 + Relu_55
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_50 and DequantizeLinear_53) into Conv_54 + Relu_55
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_58
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_50
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_53
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_65 + Relu_66
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_69 into Conv_65 + Relu_66
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_61 and DequantizeLinear_64) into Conv_65 + Relu_66
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_69
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_61
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_64
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_76 + Relu_77
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_72 and DequantizeLinear_75) into Conv_76 + Relu_77
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_72
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_75
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_87 + Relu_88
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_91 into Conv_87 + Relu_88
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_83 and DequantizeLinear_86) into Conv_87 + Relu_88
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_91
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_83
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_86
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_98 + Relu_99
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_102 into Conv_98 + Relu_99
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_94 and DequantizeLinear_97) into Conv_98 + Relu_99
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_102
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_94
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_97
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_109 + Relu_110
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_113 into Conv_109 + Relu_110
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_105 and DequantizeLinear_108) into Conv_109 + Relu_110
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_113
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_105
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_108
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_120 + Relu_121
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_124 into Conv_120 + Relu_121
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_116 and DequantizeLinear_119) into Conv_120 + Relu_121
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_124
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_116
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_119
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_131 + Relu_132
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_135 into Conv_131 + Relu_132
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_127 and DequantizeLinear_130) into Conv_131 + Relu_132
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_135
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_127
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_130
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_142 + Relu_143
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_148 into Conv_142 + Relu_143
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_138 and DequantizeLinear_141) into Conv_142 + Relu_143
[12/14/2023-17:14:00] [V] [TRT] Removing QuantizeLinear_148
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_138
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_141
[12/14/2023-17:14:00] [V] [TRT] Running: QuantizeDoubleInputNodes on ConvTranspose_155
[12/14/2023-17:14:00] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_151 and DequantizeLinear_154) into ConvTranspose_155
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_151
[12/14/2023-17:14:00] [V] [TRT] Removing DequantizeLinear_154
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.fuser.0.weight + QuantizeLinear_8
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.fuser.0.weight + QuantizeLinear_8 with Conv_10 + Relu_11
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 with Conv_21 + Relu_22
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 with Conv_32 + Relu_33
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 with Conv_43 + Relu_44
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 with Conv_54 + Relu_55
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 with Conv_65 + Relu_66
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 with Conv_76 + Relu_77
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 with Conv_87 + Relu_88
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 with Conv_98 + Relu_99
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 with Conv_109 + Relu_110
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 with Conv_120 + Relu_121
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 with Conv_131 + Relu_132
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 with Conv_142 + Relu_143
[12/14/2023-17:14:00] [V] [TRT] Running: ConstWeightsFusion on parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153
[12/14/2023-17:14:00] [V] [TRT] ConstWeightsFusion: Fusing parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 with ConvTranspose_155
[12/14/2023-17:14:00] [V] [TRT] After dupe layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After final dead-layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After tensor merging: 21 layers
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer quantization epilogue pass
[12/14/2023-17:14:00] [V] [TRT] QDQ optimization pass
[12/14/2023-17:14:00] [V] [TRT] QDQ graph optimizer constant fold dangling QDQ pass
[12/14/2023-17:14:00] [V] [TRT] Running: QDQToCopy on QuantizeLinear_3_clone_1
[12/14/2023-17:14:00] [V] [TRT] Swap the layer type of QuantizeLinear_3_clone_1 from QUANTIZE to kQDQ
[12/14/2023-17:14:00] [V] [TRT] Running: QDQToCopy on QuantizeLinear_3_clone_0
[12/14/2023-17:14:00] [V] [TRT] Swap the layer type of QuantizeLinear_3_clone_0 from QUANTIZE to kQDQ
[12/14/2023-17:14:00] [V] [TRT] Running: QDQToCopy on QuantizeLinear_80
[12/14/2023-17:14:00] [V] [TRT] Swap the layer type of QuantizeLinear_80 from QUANTIZE to kQDQ
[12/14/2023-17:14:00] [V] [TRT] After dupe layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After final dead-layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After tensor merging: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After vertical fusions: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After dupe layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After final dead-layer removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After tensor merging: 21 layers
[12/14/2023-17:14:00] [V] [TRT] After slice removal: 21 layers
[12/14/2023-17:14:00] [V] [TRT] Eliminating concatenation Concat_158
[12/14/2023-17:14:00] [V] [TRT] Retargeting 595 to middle
[12/14/2023-17:14:00] [V] [TRT] Retargeting 609 to middle
[12/14/2023-17:14:00] [V] [TRT] Eliminating concatenation Concat_0
[12/14/2023-17:14:00] [V] [TRT] Generating copy for Concat_0_camera_clone_0 to 427 because of stomping hazard.
[12/14/2023-17:14:00] [V] [TRT] Retargeting Concat_0_lidar_clone_1 to 427
[12/14/2023-17:14:00] [V] [TRT] After concat removal: 20 layers
[12/14/2023-17:14:00] [V] [TRT] Trying to split Reshape and strided tensor
[12/14/2023-17:14:00] [I] [TRT] Graph optimization time: 0.0115427 seconds.
[12/14/2023-17:14:00] [V] [TRT] Building graph using backend strategy 2
[12/14/2023-17:14:00] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[12/14/2023-17:14:00] [V] [TRT] Constructing optimization profile number 0 [1/1].
[12/14/2023-17:14:00] [V] [TRT] Applying generic optimizations to the graph for inference.
[12/14/2023-17:14:00] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[12/14/2023-17:14:00] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(10886400,32400,180,1) -> Int8(8294400,32400,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(2721600,32400:4,180,1) -> Int8(2073600,32400:4,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 1.01581
[12/14/2023-17:14:00] [V] [TRT] parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009]) profiling completed in 0.0111316 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 1.01581
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(2721600,32400:4,180,1) -> Int8(259200,32400:32,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 1.14955
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 1.04594
[12/14/2023-17:14:00] [V] [TRT] parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009]) profiling completed in 0.0249329 seconds. Fastest Tactic: 0xeb494e2e67f079d4 Time: 1.04594
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb494e2e67f079d4
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(356400,32400:32,180,1) -> Int8(259200,32400:32,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.193682
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.261266
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.230107
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.215771
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.575543
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.236983
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.259351
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.235227
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.479511
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.516096
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.214935
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.217838
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.231131
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.423365
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.220599
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.343333
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.447049
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.410592
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.247369
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.53093
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.525166
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.428471
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.421157
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.432567
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.523118
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.221477
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.420462
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.211717
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.220306
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.194267
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.192512
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.585143
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.196315
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.435099
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.638098
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.584119
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.209189
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.615424
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.480256
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.230107
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.22133
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.227904
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.463726
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.207035
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.231863
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.430665
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.406267
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.243712
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.223963
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.417842
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.194811
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.21179
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.215625
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.209189
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.519022
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.258606
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.239662
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.192951
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.220018
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.363666
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.208603
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.247369
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.369518
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.230546
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.318318
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.231424
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.244923
[12/14/2023-17:14:00] [V] [TRT] parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskConvolution[0x80000009]) profiling completed in 0.426827 seconds. Fastest Tactic: 0xf33711e7c9ed4673 Time: 0.192512
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf33711e7c9ed4673
[12/14/2023-17:14:00] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(8294400,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(2073600,32400:4,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.409893
[12/14/2023-17:14:00] [V] [TRT] parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009]) profiling completed in 0.00602205 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.409893
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(2073600,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.412274
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.370688
[12/14/2023-17:14:00] [V] [TRT] parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009]) profiling completed in 0.0127131 seconds. Fastest Tactic: 0xeb494e2e67f079d4 Time: 0.370688
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:00] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb494e2e67f079d4
[12/14/2023-17:14:00] [V] [TRT] *************** Autotuning format combination: Int8(259200,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:00] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0816274
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.110144
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.0906971
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.113664
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.164425
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0904777
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.105326
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.172763
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.129952
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.158866
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.113065
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0910629
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0890149
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.140727
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0996206
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.12405
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.113152
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.114542
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.102107
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.156041
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.141312
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.126642
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.114176
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.105984
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.151392
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.162816
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.141342
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0923177
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.161792
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0830171
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0823474
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.157111
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0837486
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.119349
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.338651
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.319195
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0911749
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.165303
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.152869
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.168704
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0946537
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0959634
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.130953
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0903314
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0891703
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.162816
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.141605
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0943543
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0965486
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.140142
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0828709
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0889417
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0896777
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.091136
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.179785
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.108325
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0992549
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0807497
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0990834
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.123392
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.087552
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.106496
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.162377
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.169253
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.104425
[12/14/2023-17:14:00] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0925074
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.0953051
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskConvolution[0x80000009]) profiling completed in 0.30658 seconds. Fastest Tactic: 0x70ccdad7e8ced9ab Time: 0.0807497
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x70ccdad7e8ced9ab
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.161353
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009]) profiling completed in 0.00427102 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.161353
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.16085
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.161938
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009]) profiling completed in 0.00917531 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.16085
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0472743
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0620312
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.0533943
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0625615
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.0912571
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0509272
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0644145
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0942811
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0722651
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0907703
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0620541
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0545204
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0503223
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0759931
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0565638
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0717531
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.067584
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0629029
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0600747
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.08704
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0844069
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0719771
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0631467
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0606034
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0835291
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0904846
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0774583
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0540282
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0895269
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0464823
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0461166
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0893074
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0476373
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0730697
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.144123
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.139842
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0527604
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0932571
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.0847634
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0922674
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0578316
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0597821
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0730743
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.052029
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0505173
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0909577
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0765349
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0545189
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0552777
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0765806
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0469474
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0543695
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0531596
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.0529554
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.107813
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.0606613
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0579139
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0462263
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0562255
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.0695634
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0526141
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.060419
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.0901851
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0929006
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0597745
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0549059
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.0543482
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskConvolution[0x80000009]) profiling completed in 0.363329 seconds. Fastest Tactic: 0xf33711e7c9ed4673 Time: 0.0461166
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf33711e7c9ed4673
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2 Time: 0.153161
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99 Time: 0.165303
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009]) profiling completed in 0.00734372 seconds. Fastest Tactic: 0x69c4e2ca38eadce2 Time: 0.153161
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x69c4e2ca38eadce2
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xac914b235d066808 Time: 0.0783131
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x2bcbba39f608bf10 Time: 0.075776
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xa8b56a226b057463 Time: 0.0749714
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84 Time: 0.0856206
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x23b890da05937b9e Time: 0.0533592
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009]) profiling completed in 0.0181773 seconds. Fastest Tactic: 0x23b890da05937b9e Time: 0.0533592
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x23b890da05937b9e
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Float(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e Time: 0.0781966
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x45f7566cdb2b10fb Time: 0.0852343
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0edd5d0285e564d4 Time: 0.0629806
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a Time: 0.0857966
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x47b1629a4bff4800 Time: 0.069853
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e Time: 0.0757029
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xad886d4d69834922 Time: 0.0650088
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33 Time: 0.0716069
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1 Time: 0.0665021
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377 Time: 0.0704122
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e Time: 0.0609036
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79 Time: 0.0705097
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87 Time: 0.0864023
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2d8ab2aa0639fda9 Time: 0.0590994
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xb936321f82fd390c Time: 0.0700221
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x55edef142e02adaa Time: 0.0695299
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4 Time: 0.109714
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0e07dc8353bf7e9f Time: 0.0705097
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea2b7420057a01c1 Time: 0.109886
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61 Time: 0.0641981
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda Time: 0.093824
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec Time: 0.086016
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd14bd6d95fefd45e Time: 0.0917943
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009]) profiling completed in 0.0953329 seconds. Fastest Tactic: 0x2d8ab2aa0639fda9 Time: 0.0590994
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x2d8ab2aa0639fda9
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Half(129600,32400:32,180,1) ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x43e3804f158e597d Time: 0.0554423
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xfa6c413ca4875a2e Time: 0.0540358
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb7a90e7097d64877 Time: 0.0552442
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3e116db8858d0d41 Time: 0.0552015
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5812ced7874b44d1 Time: 0.0568076
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xaceaca2c82ab40f3 Time: 0.0928183
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x45aada088ffff645 Time: 0.0943383
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xe830ccb2c17abf84 Time: 0.0555398
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x39d4f216f0f6dbdb Time: 0.0675535
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xad6872a374321f7e Time: 0.0538819
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xd7985d83133bcf37 Time: 0.0738789
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x264d83735b1cba13 Time: 0.0562133
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x4e7f02f91ddf4673 Time: 0.0560411
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4133eb8759ee0d6d Time: 0.0554347
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x8f07802f58d278c0 Time: 0.0949371
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xe266dbc8b588209b Time: 0.0541257
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xccdb99df0646c7b3 Time: 0.0852846
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xc5159665a920f22c Time: 0.0852114
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x51a916d02de43689 Time: 0.0903589
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xe2bc5a4963d23ad0 Time: 0.0550918
[12/14/2023-17:14:01] [V] [TRT] parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskConvolution[0x80000009]) profiling completed in 0.0812846 seconds. Fastest Tactic: 0xad6872a374321f7e Time: 0.0538819
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xad6872a374321f7e
[12/14/2023-17:14:01] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:01] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:01] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.125367
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.124928
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24 Time: 0.124217
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.122651
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R1_S1_U1_V1 Tactic: 0x588a737570bcf22b Time: 0.66955
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C1_R1_S1_U1_V1 Tactic: 0xd646964a96ca001d Time: 0.399675
[12/14/2023-17:14:01] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C4_R1_S1_U1_V1 Tactic: 0xc0bfd75233df14d7 Time: 0.534528
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C8_R1_S1_U1_V1 Tactic: 0x80a5d7e9c9c4b8ce Time: 0.399067
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.222354
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0x001526e231ae2e51 Time: 0.735145
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675 Time: 0.152229
[12/14/2023-17:14:02] [V] [TRT] Fast skip Tactic:0x46094dd94e60f58a which exceed time limit during pre-run
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ1_C1_R1_S1_U1_V1 Tactic: 0x46094dd94e60f58a Time: 2.58662
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x361add5e7e5ba900 Time: 0.465335
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C2_R1_S1_U1_V1 Tactic: 0x55214d4ab35e0b9d Time: 0.469723
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x95559a386f1ab48c Time: 0.443538
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x06122dede8a04ac8 Time: 0.42496
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.230121
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0xdfbf20bf5c5ed39e Time: 0.492544
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x8c2df094ce3399e7 Time: 0.436517
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ9_C8_R1_S1_U1_V1 Tactic: 0xdb776069eecca7f3 Time: 0.341285
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.138167
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0x5c06dd7da7ff5d89 Time: 0.320219
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0xe7c1b91b9c2edfa3 Time: 0.39029
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C1_R1_S1_U1_V1 Tactic: 0x053bede31607189f Time: 0.402578
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd Time: 0.139202
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x2f62b7f2df72846b Time: 0.312905
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0xadc24b6dce6a94cc Time: 0.372329
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xe3a8b64d995c2040 Time: 0.419986
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.375077
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C4_R1_S1_U1_V1 Tactic: 0xc6c6d590dfdf6d0c Time: 0.404773
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C4_R1_S1_U1_V1 Tactic: 0x3652da2fa8bb0ef3 Time: 0.403017
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP8_TQ2_C8_R1_S1_U1_V1 Tactic: 0x84b1c619b722ac50 Time: 0.589184
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x27fd6918968ac741 Time: 0.488448
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0x74f998800c32af5c Time: 0.881957
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C4_R1_S1_U1_V1 Tactic: 0x0b22bb41cc7dfe7d Time: 0.431543
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.185344
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C8_R1_S1_U1_V1 Tactic: 0x6867dd944a05c100 Time: 0.479963
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.161646
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0x606e22cd0b28a04e Time: 0.485897
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ8_C2_R1_S1_U1_V1 Tactic: 0x4d77488847fb11ac Time: 0.811762
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e Time: 0.138386
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303 Time: 0.144969
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x1b34d9288dbdb108 Time: 0.482304
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.220891
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0xc32165ab1a69bdc2 Time: 0.474843
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP1_TQ10_C2_R1_S1_U1_V1 Tactic: 0x9140485476980e7c Time: 0.507319
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C2_R1_S1_U1_V1 Tactic: 0x4ccf06551aa20492 Time: 0.510793
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0xf119544b988c92ed Time: 0.437207
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ10_C1_R1_S1_U1_V1 Tactic: 0xc48d91bc4c36e826 Time: 0.55413
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338 Time: 0.117394
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x8b8488312a95988c Time: 0.431104
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP3_TQ9_C4_R1_S1_U1_V1 Tactic: 0x947bf5563a9683d6 Time: 0.434469
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP8_TQ2_C2_R1_S1_U1_V1 Tactic: 0xb1208f5cd1618214 Time: 0.78427
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x91aab4dd62bd690b Time: 0.457728
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ5_C2_R1_S1_U1_V1 Tactic: 0xbdab4046e67fd5a0 Time: 0.546523
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.150674
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0x5df694d12c46ef44 Time: 0.526336
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C1_R1_S1_U1_V1 Tactic: 0x4879b042e34ded1f Time: 0.503488
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C4_R1_S1_U1_V1 Tactic: 0x2fbc9130014701fc Time: 0.507465
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C1_R1_S1_U1_V1 Tactic: 0x13e300b312a555d1 Time: 0.537746
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x2b9d9917d2d559ec Time: 0.578121
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ8_C1_R1_S1_U1_V1 Tactic: 0x40ae69d97c5509c6 Time: 0.539794
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.125294
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ8_C2_R1_S1_U1_V1 Tactic: 0xbc130e9bbb26c09e Time: 0.498542
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C8_R1_S1_U1_V1 Tactic: 0xd3a0b9f271d4432a Time: 0.475575
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0x5100456d60cc538d Time: 0.562469
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0xceceb54abc5a9fbb Time: 0.732352
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.148334
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27 Time: 0.117088
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0xe631f0b717976d6e Time: 0.494299
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0xda590f07bb4090a9 Time: 0.43403
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0x65880d75ec36e379 Time: 0.550766
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0xba220b2881c61eb6 Time: 0.633417
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0x4f9a95a9a8862c25 Time: 0.476453
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xeb3768a7d0a4636a Time: 0.494432
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0x89b449623e8b546b Time: 0.508489
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x77ff66671dd929ae Time: 0.520631
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0x79164861aa018d25 Time: 0.531163
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C4_R1_S1_U1_V1 Tactic: 0x269b010715e657e8 Time: 0.467675
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x0b33f9e893e376e6 Time: 0.41984
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C2_R1_S1_U1_V1 Tactic: 0xbc5b09ea6dc6676d Time: 0.449097
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.13824
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0xfe1903b4a84feabf Time: 0.452754
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x13ab07c2c445f222 Time: 0.839442
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C2_R1_S1_U1_V1 Tactic: 0xefc84642dd03beed Time: 0.468992
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0x4ec6e5a90546faa3 Time: 0.504539
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96 Time: 0.143909
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.149065
[12/14/2023-17:14:02] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.590732 seconds. Fastest Tactic: 0xc3cf6e1d1c6aff27 Time: 0.117088
[12/14/2023-17:14:02] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:02] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:02] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CudnnConvolution[0x80000000])
[12/14/2023-17:14:02] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:02] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:02] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc3cf6e1d1c6aff27
[12/14/2023-17:14:02] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:02] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.127195
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.125513
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24 Time: 0.124613
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.123319
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R1_S1_U1_V1 Tactic: 0x588a737570bcf22b Time: 0.740233
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.173202
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C1_R1_S1_U1_V1 Tactic: 0xd646964a96ca001d Time: 0.468114
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C4_R1_S1_U1_V1 Tactic: 0xc0bfd75233df14d7 Time: 0.594505
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C8_R1_S1_U1_V1 Tactic: 0x80a5d7e9c9c4b8ce Time: 0.487131
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.223086
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.156087
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0x001526e231ae2e51 Time: 0.786432
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675 Time: 0.149445
[12/14/2023-17:14:02] [V] [TRT] Fast skip Tactic:0x46094dd94e60f58a which exceed time limit during pre-run
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ1_C1_R1_S1_U1_V1 Tactic: 0x46094dd94e60f58a Time: 2.66752
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x361add5e7e5ba900 Time: 0.40341
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C2_R1_S1_U1_V1 Tactic: 0x55214d4ab35e0b9d Time: 0.463141
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x95559a386f1ab48c Time: 0.440155
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x06122dede8a04ac8 Time: 0.450423
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.230702
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0xdfbf20bf5c5ed39e Time: 0.517705
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x8c2df094ce3399e7 Time: 0.471625
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ9_C8_R1_S1_U1_V1 Tactic: 0xdb776069eecca7f3 Time: 0.464311
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.139118
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0x5c06dd7da7ff5d89 Time: 0.463095
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0xe7c1b91b9c2edfa3 Time: 0.506734
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C1_R1_S1_U1_V1 Tactic: 0x053bede31607189f Time: 0.507173
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd Time: 0.14219
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x2f62b7f2df72846b Time: 0.413403
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0xadc24b6dce6a94cc Time: 0.559113
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xe3a8b64d995c2040 Time: 0.376686
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.507168
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C4_R1_S1_U1_V1 Tactic: 0xc6c6d590dfdf6d0c Time: 0.389266
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C4_R1_S1_U1_V1 Tactic: 0x3652da2fa8bb0ef3 Time: 0.446464
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP8_TQ2_C8_R1_S1_U1_V1 Tactic: 0x84b1c619b722ac50 Time: 0.539214
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x27fd6918968ac741 Time: 0.411502
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1 Time: 0.150674
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0x74f998800c32af5c Time: 0.848165
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C4_R1_S1_U1_V1 Tactic: 0x0b22bb41cc7dfe7d Time: 0.488512
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.186514
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C8_R1_S1_U1_V1 Tactic: 0x6867dd944a05c100 Time: 0.501614
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.161207
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.158427
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505 Time: 0.141458
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7 Time: 0.155502
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0x606e22cd0b28a04e Time: 0.490789
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a Time: 0.143506
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ8_C2_R1_S1_U1_V1 Tactic: 0x4d77488847fb11ac Time: 0.690615
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e Time: 0.138533
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303 Time: 0.144969
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b Time: 0.113371
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x1b34d9288dbdb108 Time: 0.471771
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.220599
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0xc32165ab1a69bdc2 Time: 0.414427
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP1_TQ10_C2_R1_S1_U1_V1 Tactic: 0x9140485476980e7c Time: 0.43915
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C2_R1_S1_U1_V1 Tactic: 0x4ccf06551aa20492 Time: 0.513317
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x16_stage2_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe52b0ddb126aa135 Time: 0.102297
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0xf119544b988c92ed Time: 0.419694
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ10_C1_R1_S1_U1_V1 Tactic: 0xc48d91bc4c36e826 Time: 0.505856
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4 Time: 0.14965
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338 Time: 0.11707
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x8b8488312a95988c Time: 0.443433
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP3_TQ9_C4_R1_S1_U1_V1 Tactic: 0x947bf5563a9683d6 Time: 0.43008
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd Time: 0.153609
[12/14/2023-17:14:02] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP8_TQ2_C2_R1_S1_U1_V1 Tactic: 0xb1208f5cd1618214 Time: 0.778533
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x91aab4dd62bd690b Time: 0.45685
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ5_C2_R1_S1_U1_V1 Tactic: 0xbdab4046e67fd5a0 Time: 0.456288
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.148919
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77 Time: 0.185637
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0x5df694d12c46ef44 Time: 0.479086
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C1_R1_S1_U1_V1 Tactic: 0x4879b042e34ded1f Time: 0.58485
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C4_R1_S1_U1_V1 Tactic: 0x2fbc9130014701fc Time: 0.456137
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C1_R1_S1_U1_V1 Tactic: 0x13e300b312a555d1 Time: 0.489326
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x2b9d9917d2d559ec Time: 0.534235
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ8_C1_R1_S1_U1_V1 Tactic: 0x40ae69d97c5509c6 Time: 0.498103
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.125221
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ8_C2_R1_S1_U1_V1 Tactic: 0xbc130e9bbb26c09e Time: 0.491081
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C8_R1_S1_U1_V1 Tactic: 0xd3a0b9f271d4432a Time: 0.395118
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0x5100456d60cc538d Time: 0.523694
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x32x16_stage2_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xb2c8ebee321e63d6 Time: 0.117991
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0xceceb54abc5a9fbb Time: 0.789358
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.148187
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27 Time: 0.117029
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0xe631f0b717976d6e Time: 0.468233
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0xda590f07bb4090a9 Time: 0.47499
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0x65880d75ec36e379 Time: 0.497079
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0xba220b2881c61eb6 Time: 0.588786
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0x4f9a95a9a8862c25 Time: 0.449893
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xeb3768a7d0a4636a Time: 0.458606
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0x89b449623e8b546b Time: 0.426862
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x77ff66671dd929ae Time: 0.476251
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0x79164861aa018d25 Time: 0.433152
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C4_R1_S1_U1_V1 Tactic: 0x269b010715e657e8 Time: 0.469536
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x0b33f9e893e376e6 Time: 0.413842
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C2_R1_S1_U1_V1 Tactic: 0xbc5b09ea6dc6676d Time: 0.323584
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.137216
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0xfe1903b4a84feabf Time: 0.392338
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x13ab07c2c445f222 Time: 0.611598
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C2_R1_S1_U1_V1 Tactic: 0xefc84642dd03beed Time: 0.371273
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0x4ec6e5a90546faa3 Time: 0.423351
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96 Time: 0.143214
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.147017
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.670784 seconds. Fastest Tactic: 0xe52b0ddb126aa135 Time: 0.102297
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CudnnConvolution[0x80000000])
[12/14/2023-17:14:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xe52b0ddb126aa135
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(16588800,1,92160,512) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.141678
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.20085
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484 Time: 0.129337
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86 Time: 0.147182
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.151698
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb Time: 0.145554
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.147456
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.246491
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.191342
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d Time: 0.127927
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.214016
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.130341
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.166766
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.0624958 seconds. Fastest Tactic: 0x55d80c17b1cd982d Time: 0.127927
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020399 Time: 0.0787726
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002059f Time: 0.074048
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020391 Time: 0.080896
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020531 Time: 0.0833783
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002027d Time: 0.102304
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020296 Time: 0.0975726
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206ea Time: 0.106037
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020511 Time: 0.105838
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002039b Time: 0.0992549
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020396 Time: 0.100133
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020482 Time: 0.105765
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002042b Time: 0.103643
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c8 Time: 0.104478
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f8 Time: 0.105033
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020136 Time: 0.111714
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c0 Time: 0.112201
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.0769132 seconds. Fastest Tactic: 0x000000000002059f Time: 0.074048
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002059f
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(8294400,1,46080,256) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.141678
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.200997
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484 Time: 0.12939
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86 Time: 0.146441
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537 Time: 0.12827
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.150967
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0 Time: 0.144384
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808 Time: 0.145266
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb Time: 0.144974
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.147749
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.246345
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939 Time: 0.155648
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22 Time: 0.140727
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a Time: 0.188695
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.191113
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d Time: 0.127749
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.213495
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.130224
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.166766
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.102664 seconds. Fastest Tactic: 0x55d80c17b1cd982d Time: 0.127749
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:03] [V] [TRT] CaskGemmConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x55d80c17b1cd982d
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.109495
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_alignc4 Tactic: 0xc8ad2c0ce0af5623 Time: 0.105547
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.107083
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.105447
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x1d144cf9675b8d6f Time: 0.103863
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.106569
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.0316459 seconds. Fastest Tactic: 0x1d144cf9675b8d6f Time: 0.103863
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1d144cf9675b8d6f
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,1:4,23040,128) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.150363
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.126245
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.127342
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4 Time: 0.126453
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7 Time: 0.14763
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3 Time: 0.116663
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b Time: 0.105637
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.104309
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.104082
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.0514055 seconds. Fastest Tactic: 0x65e41d81f093b482 Time: 0.104082
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020399 Time: 0.0781897
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002059f Time: 0.073504
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020391 Time: 0.0817737
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020531 Time: 0.0827246
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002027d Time: 0.1024
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020296 Time: 0.0979383
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206ea Time: 0.105179
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020511 Time: 0.105253
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002039b Time: 0.0985966
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020396 Time: 0.0996206
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020482 Time: 0.104741
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002042b Time: 0.102779
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c8 Time: 0.103081
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f8 Time: 0.104375
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020136 Time: 0.111104
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c0 Time: 0.111259
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.0714741 seconds. Fastest Tactic: 0x000000000002059f Time: 0.073504
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002059f
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.109349
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_alignc4 Tactic: 0x440241d9c93d605d Time: 0.104009
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_alignc4 Tactic: 0xc8ad2c0ce0af5623 Time: 0.106146
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.107666
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x608ed7b5923d2355 Time: 0.104057
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.105179
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x1d144cf9675b8d6f Time: 0.104816
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.105545
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.0445751 seconds. Fastest Tactic: 0x440241d9c93d605d Time: 0.104009
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x440241d9c93d605d
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(2073600,1:4,11520,64) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.150528
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.126464
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.12661
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4 Time: 0.126318
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7 Time: 0.147346
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3 Time: 0.116217
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b Time: 0.106062
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462 Time: 0.104517
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.106206
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.105998
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.0470899 seconds. Fastest Tactic: 0x9dece0dc37e90462 Time: 0.104517
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020399 Time: 0.0779703
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002059f Time: 0.0735017
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020391 Time: 0.080208
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020531 Time: 0.0831017
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002027d Time: 0.103367
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020296 Time: 0.0982011
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206ea Time: 0.104011
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020511 Time: 0.104521
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002039b Time: 0.09912
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020396 Time: 0.0999177
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020482 Time: 0.105778
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002042b Time: 0.103888
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c8 Time: 0.102302
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f8 Time: 0.103369
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020136 Time: 0.112151
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c0 Time: 0.112174
[12/14/2023-17:14:03] [V] [TRT] Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.0647546 seconds. Fastest Tactic: 0x000000000002059f Time: 0.0735017
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002059f
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CudnnConvolution[0x80000000])
[12/14/2023-17:14:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(8294400,32400,180,1) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CudnnConvolution[0x80000000])
[12/14/2023-17:14:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(8294400,32400:2,180,1) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(4147200,32400:2,180,1) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(8294400,1:2,46080,256) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(4147200,1:2,23040,128) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(4147200,1:4,23040,128) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(2073600,1:4,11520,64) ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:03] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:03] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(2073600,1:8,11520,64) long-strided ***************
[12/14/2023-17:14:03] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0599771
[12/14/2023-17:14:03] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xb4ed47991b2d81ae Time: 0.052803
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x3e2d344492eaa731 Time: 0.0531017
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.050752
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x4a33d90483c0ec01 Time: 0.046128
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0435931
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0550674
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8f25d6cdaeaaa100 Time: 0.054467
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xd80cb0f3373aef38 Time: 0.0495451
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0457451
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2e9f40fea3fe4d65 Time: 0.0604648
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0505585
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.104037
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0509166
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0535406
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.10136
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xbb4ac900a7be8b4c Time: 0.0648533
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0538651
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0497859
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0661425
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0435634
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0553524
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0502918
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0535558
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0610011
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.053053
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xea50b6d3d87bf5dd Time: 0.043264
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0502796
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0496396
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2aa016c86360697f Time: 0.0981577
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0673813
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x9d78040b7e8c8ac7 Time: 0.0498347
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0662964
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0562926
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0492495
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8e1e99c68a674ff4 Time: 0.0521295
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0450549
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x23848f7cc4e20635 Time: 0.0505036
[12/14/2023-17:14:04] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.179298 seconds. Fastest Tactic: 0xea50b6d3d87bf5dd Time: 0.043264
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] Conv_144 + Relu_145: 88 available tactics, 0 unparsable, 44 pruned, 44 remaining after tactic pruning.
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020969 Time: 0.101735
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002072e Time: 0.103333
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020985 Time: 0.103351
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020477 Time: 0.104784
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020552 Time: 0.106601
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020849 Time: 0.107762
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002003c Time: 0.0482651
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020193 Time: 0.0482728
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020057 Time: 0.0480792
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a5 Time: 0.0466617
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020941 Time: 0.112421
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205c7 Time: 0.109993
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020020 Time: 0.0503345
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002044c Time: 0.0520777
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a6 Time: 0.0548571
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203cb Time: 0.054947
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020353 Time: 0.102667
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200f6 Time: 0.103205
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002077c Time: 0.0408057
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d9 Time: 0.0417646
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020749 Time: 0.0474697
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204da Time: 0.0481067
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020156 Time: 0.11403
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207e5 Time: 0.114103
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f0 Time: 0.0496884
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206dc Time: 0.0505509
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202b4 Time: 0.108421
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002078c Time: 0.108544
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020782 Time: 0.0481768
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020601 Time: 0.0477379
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e8 Time: 0.0477379
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d1 Time: 0.0489783
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207c6 Time: 0.0599604
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002054f Time: 0.0598187
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002092f Time: 0.106789
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020008 Time: 0.106434
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205f8 Time: 0.0482697
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020413 Time: 0.0496792
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002007d Time: 0.0503619
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e7 Time: 0.0493958
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203fc Time: 0.0539093
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020673 Time: 0.0547109
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208fb Time: 0.0502735
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002091e Time: 0.0500175
[12/14/2023-17:14:04] [V] [TRT] Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.534835 seconds. Fastest Tactic: 0x000000000002077c Time: 0.0408057
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:04] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002077c
[12/14/2023-17:14:04] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:04] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(1036800,1:8,5760,32) ***************
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0603185
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xb4ed47991b2d81ae Time: 0.0530377
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x3e2d344492eaa731 Time: 0.0526354
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0506636
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x4a33d90483c0ec01 Time: 0.0466651
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x8047bcfcebface4a Time: 0.0513463
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xa2121200e08f5391 Time: 0.0441429
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0444606
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0547596
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8f25d6cdaeaaa100 Time: 0.0542933
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xd80cb0f3373aef38 Time: 0.0493958
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0461474
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2e9f40fea3fe4d65 Time: 0.0605135
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xfd2247f786006d58 Time: 0.0456149
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0507337
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.103856
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0511025
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0533135
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.101099
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xbb4ac900a7be8b4c Time: 0.0649387
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0537554
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0494933
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0660282
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.044656
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3fc555ff414cee06 Time: 0.0521173
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.054941
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x454d6448fb6e7fd1 Time: 0.051456
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0503086
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0535406
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0609874
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0532678
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3ca70d6b51bf2164 Time: 0.0580267
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x361d222e42fcb76c Time: 0.0653684
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xea50b6d3d87bf5dd Time: 0.0439463
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0500236
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0498636
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x5cf18273fea3db5c Time: 0.0489646
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2aa016c86360697f Time: 0.0978811
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0675459
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x9d78040b7e8c8ac7 Time: 0.0500785
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0663741
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3e55aa5fb58280dd Time: 0.0508389
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0559832
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0490011
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xe69f3e9fcc7b2069 Time: 0.0946469
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3eda3b336995a6f0 Time: 0.0493013
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x7a738fe099ae3c1e Time: 0.0524282
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8e1e99c68a674ff4 Time: 0.0508206
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0453737
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x23848f7cc4e20635 Time: 0.0505661
[12/14/2023-17:14:04] [V] [TRT] Conv_144 + Relu_145 (CaskConvolution[0x80000009]) profiling completed in 0.239347 seconds. Fastest Tactic: 0xea50b6d3d87bf5dd Time: 0.0439463
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:04] [V] [TRT] Conv_144 + Relu_145: 88 available tactics, 0 unparsable, 44 pruned, 44 remaining after tactic pruning.
[12/14/2023-17:14:04] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e])
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020969 Time: 0.101239
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002072e Time: 0.103351
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020985 Time: 0.103351
[12/14/2023-17:14:04] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020477 Time: 0.104814
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020552 Time: 0.105838
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020849 Time: 0.107195
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002003c Time: 0.0486644
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020193 Time: 0.0477867
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020057 Time: 0.0482255
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a5 Time: 0.0468091
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020941 Time: 0.110519
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205c7 Time: 0.110002
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020020 Time: 0.0495665
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002044c Time: 0.0509943
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a6 Time: 0.0550857
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203cb Time: 0.0547185
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020353 Time: 0.102693
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200f6 Time: 0.103205
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002077c Time: 0.0418926
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d9 Time: 0.0423383
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020749 Time: 0.0474823
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204da Time: 0.047843
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020156 Time: 0.113975
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207e5 Time: 0.113957
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f0 Time: 0.0492297
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206dc Time: 0.0499398
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202b4 Time: 0.108617
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002078c Time: 0.108398
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020782 Time: 0.0479269
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020601 Time: 0.0476526
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e8 Time: 0.047376
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d1 Time: 0.0484069
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207c6 Time: 0.059488
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002054f Time: 0.0594682
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002092f Time: 0.104647
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020008 Time: 0.106057
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205f8 Time: 0.0476373
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020413 Time: 0.0496579
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002007d Time: 0.0506103
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e7 Time: 0.0506636
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203fc Time: 0.0542187
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020673 Time: 0.0545143
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208fb Time: 0.0501272
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002091e Time: 0.0511025
[12/14/2023-17:14:05] [V] [TRT] Conv_144 + Relu_145 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.182492 seconds. Fastest Tactic: 0x000000000002077c Time: 0.0418926
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002077c
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(1036800,1:16,5760,32) long-strided ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(518400,1:16,2880,16) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Half(129600,32400:32,180,1) -> Half(518400,32400:32,180,1) long-strided ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Half(129600,32400:32,180,1) -> Half(259200,32400:32,180,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CublasConvolution[0x80000029])
[12/14/2023-17:14:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: Conv_144 + Relu_145 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(4147200,32400,180,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0953051
[12/14/2023-17:14:05] [V] [TRT] parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009]) profiling completed in 0.00448129 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.0953051
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(1036800,32400:4,180,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0950126
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0963291
[12/14/2023-17:14:05] [V] [TRT] parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009]) profiling completed in 0.00919531 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.0950126
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(129600,32400:32,180,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0294921
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0385314
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.0341833
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0309833
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.055491
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0264198
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.039976
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0266743
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0383394
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0488594
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0305033
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0343771
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0262964
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0375223
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0390297
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.045568
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.0423131
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0393051
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0373017
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0522118
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0491413
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.045104
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.039328
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0383269
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0499017
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0390114
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0350793
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0291694
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0386206
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0295863
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0292069
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0473966
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0321902
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0441509
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0931589
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.0885897
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.028371
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0566095
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.0514118
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0262415
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0381806
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0392411
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0388309
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0278011
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0266156
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0390217
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0381314
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0379246
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0292763
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0344704
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.031605
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0343003
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0332133
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.028531
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0598659
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.0382869
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0355401
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0296082
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0383634
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.0434457
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0336037
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.032341
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.0386617
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0264053
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0374857
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0367909
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.0378251
[12/14/2023-17:14:05] [V] [TRT] parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskConvolution[0x80000009]) profiling completed in 0.309699 seconds. Fastest Tactic: 0x554e2e252e28b3fd Time: 0.0262415
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x554e2e252e28b3fd
[12/14/2023-17:14:05] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(2073600,8100,90,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.182144
[12/14/2023-17:14:05] [V] [TRT] parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009]) profiling completed in 0.00436778 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.182144
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.182126
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.185783
[12/14/2023-17:14:05] [V] [TRT] parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009]) profiling completed in 0.00996694 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.182126
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[12/14/2023-17:14:05] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:05] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009])
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0473589
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.062816
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.0507368
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0517851
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.086016
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0451657
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0632335
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0455349
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0662674
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0776046
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0513463
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0528091
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0444343
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0646583
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0660724
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0717531
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.0625128
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0676724
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.059555
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.083456
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.077312
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.077008
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0674377
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0608884
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0787749
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.06672
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0584015
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0468743
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.066365
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0506636
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0503771
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0765074
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0515672
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0659749
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.133328
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.128971
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0467954
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0871131
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.0804571
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0448366
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0552259
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0566126
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.066723
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0463623
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0446057
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0664716
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0649021
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0535893
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0494446
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0576853
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0509166
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0521265
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0516526
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.046336
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0947931
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.061888
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0577829
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0471097
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.065536
[12/14/2023-17:14:05] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.07424
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0506027
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0542811
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.0663086
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0451794
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0579185
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0523429
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.0538377
[12/14/2023-17:14:06] [V] [TRT] parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskConvolution[0x80000009]) profiling completed in 0.356764 seconds. Fastest Tactic: 0xf8d4389f60adfa3c Time: 0.0444343
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:06] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf8d4389f60adfa3c
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(2073600,8100,90,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110 (CaskConvolution[0x80000009])
[12/14/2023-17:14:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:06] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(2073600,8100,90,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121 (CaskConvolution[0x80000009])
[12/14/2023-17:14:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:06] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(2073600,8100,90,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132 (CaskConvolution[0x80000009])
[12/14/2023-17:14:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:06] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(2073600,8100,90,1) -> Int8(2073600,8100,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143 (CaskConvolution[0x80000009])
[12/14/2023-17:14:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143 (CaskFlattenConvolution[0x80000036])
[12/14/2023-17:14:06] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(518400,8100:4,90,1) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CudnnDeconvolution[0x80000002])
[12/14/2023-17:14:06] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (GemmDeconvolution[0x80000010])
[12/14/2023-17:14:06] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CaskDeconvolution[0x8000000a])
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f Time: 0.584997
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f Time: 0.579877
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2 Time: 0.540526
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc Time: 0.577801
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32 Time: 0.501175
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907 Time: 0.705563
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1 Time: 0.609024
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0 Time: 0.590409
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99 Time: 0.650386
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29 Time: 0.741417
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881 Time: 0.559982
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83 Time: 0.570368
[12/14/2023-17:14:06] [V] [TRT] parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CaskDeconvolution[0x8000000a]) profiling completed in 0.121521 seconds. Fastest Tactic: 0xff6944b17d5b2e32 Time: 0.501175
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolution Tactic: 0xff6944b17d5b2e32
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CudnnDeconvolution[0x80000002])
[12/14/2023-17:14:06] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (GemmDeconvolution[0x80000010])
[12/14/2023-17:14:06] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CaskDeconvolution[0x8000000a])
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e Time: 0.245906
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a Time: 0.231863
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef Time: 0.228791
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e Time: 0.233618
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36 Time: 0.228178
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33 Time: 0.246345
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19 Time: 0.229339
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552 Time: 0.234203
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81 Time: 0.232741
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1 Time: 0.232155
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377 Time: 0.251168
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e Time: 0.220869
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79 Time: 0.230839
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0 Time: 0.227621
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b Time: 0.218734
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437 Time: 0.230839
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87 Time: 0.239264
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664 Time: 0.217797
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190 Time: 0.23552
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93 Time: 0.231424
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e Time: 0.226889
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4 Time: 0.241957
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec Time: 0.239616
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667 Time: 0.228059
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d Time: 0.229669
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5 Time: 0.227259
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1 Time: 0.228352
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd Time: 0.24064
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c Time: 0.234935
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61 Time: 0.230377
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda Time: 0.235374
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437 Time: 0.234642
[12/14/2023-17:14:06] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec Time: 0.258304
[12/14/2023-17:14:06] [V] [TRT] parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CaskDeconvolution[0x8000000a]) profiling completed in 0.197546 seconds. Fastest Tactic: 0xa71946688cad8664 Time: 0.217797
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolution Tactic: 0xa71946688cad8664
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Int8(64800,8100:32,90,1) -> Float(259200,32400:32,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 (CaskDeconvolutionV2[0x8000002d])
[12/14/2023-17:14:06] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] =============== Computing costs for 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0836709
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.00848906 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0836709
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0836137
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.00819939 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0836137
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(16588800,1,92160,512) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(8294400,1,46080,256) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(4147200,1:4,23040,128) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(2073600,1:4,11520,64) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(16588800,32400,180,1) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0445429
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.0246523 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0445429
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0445417
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.011196 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0445417
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(8294400,32400:2,180,1) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0447269
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.0119994 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0447269
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(4147200,32400:2,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0447566
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.00877785 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0447566
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(4147200,1:2,23040,128) -> Half(8294400,1:2,46080,256) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(4147200,1:2,23040,128) -> Half(4147200,1:2,23040,128) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:4,11520,64) -> Half(4147200,1:4,23040,128) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:4,11520,64) -> Half(2073600,1:4,11520,64) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(2073600,1:8,11520,64) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0440777
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.00813567 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0440777
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(1036800,1:8,5760,32) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0441017
[12/14/2023-17:14:06] [V] [TRT] BatchNormalization_156 + Relu_157 (Scale[0x80000007]) profiling completed in 0.00811035 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0441017
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(1036800,1:16,5760,32) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(518400,1:16,2880,16) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(259200,32400:32,180,1) -> Half(518400,32400:32,180,1) long-strided ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning format combination: Half(259200,32400:32,180,1) -> Half(259200,32400:32,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: BatchNormalization_156 + Relu_157 (Scale[0x80000007])
[12/14/2023-17:14:06] [V] [TRT] Scale has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Int8(10886400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0328338
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0341696
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0328192
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_1 (Reformat[0x80000006]) profiling completed in 0.0124983 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0328192
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.075744
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0384011
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0756297
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_1 (Reformat[0x80000006]) profiling completed in 0.00841913 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0384011
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.156379
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0359086
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.156411
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_1 (Reformat[0x80000006]) profiling completed in 0.00920829 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0359086
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_1 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(2592000,32400,180,1) -> Int8(648000,32400:4,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.025597
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0160559
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0256891
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_0 (Reformat[0x80000006]) profiling completed in 0.0116379 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0160559
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(2592000,32400,180,1) -> Int8(97200,32400:32,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.057501
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.013366
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0574918
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_0 (Reformat[0x80000006]) profiling completed in 0.0119041 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.013366
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(2592000,32400,180,1) -> Int8(2592000,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0114409
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118706
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0114806
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_0 (Reformat[0x80000006]) profiling completed in 0.0168011 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0114409
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Half(2592000,32400,180,1) -> Int8(2592000:32,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 8.29505
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.221769
[12/14/2023-17:14:06] [V] [TRT] Fast skip Tactic:0x0000000000000000 which exceed time limit during pre-run
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 8.79274
[12/14/2023-17:14:06] [V] [TRT] QuantizeLinear_3_clone_0 (Reformat[0x80000006]) profiling completed in 0.0875029 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.221769
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: QuantizeLinear_3_clone_0 (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:06] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Int8(648000,32400:4,180,1) -> Int8(10886400,32400,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0264952
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171114
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0264693
[12/14/2023-17:14:06] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0147747 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0171114
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Int8(648000,32400:4,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00945572
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0151877
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0148873
[12/14/2023-17:14:06] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0156276 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00945572
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:06] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:06] [V] [TRT] *************** Autotuning Reformat: Int8(648000,32400:4,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:06] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0397897
[12/14/2023-17:14:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0157166
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0397531
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0119355 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0157166
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(97200,32400:32,180,1) -> Int8(10886400,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0381166
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0164754
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0382914
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0117645 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0164754
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(97200,32400:32,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0125486
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.015935
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00586313
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0194858 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00586313
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(97200,32400:32,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0428343
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0146222
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.042816
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0128057 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0146222
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000,32400,180,1) -> Int8(10886400,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00630599
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0102129
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00638569
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.024723 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00630599
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000,32400,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0265821
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0141469
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00817244
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0160215 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00817244
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000,32400,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0489691
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0129497
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0489524
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.0120865 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0129497
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000:32,32400,180,1) -> Int8(10886400,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104784
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.00350437 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.104784
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000:32,32400,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104814
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.00337615 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.104814
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2592000:32,32400,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10523
[12/14/2023-17:14:07] [V] [TRT] Concat_0_camera_clone_0 copy (Reformat[0x80000006]) profiling completed in 0.00347464 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.10523
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Concat_0_camera_clone_0 copy (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(10886400,32400,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(427 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.111616
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.044832
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0458354
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(427 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0127111 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.044832
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(10886400,32400,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(427 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.207579
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0403143
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.207579
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(427 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0108822 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0403143
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2721600,32400:4,180,1) -> Int8(356400,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(427 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.159598
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0472869
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0375223
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(427 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0119661 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0375223
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(356400,32400:32,180,1) -> Int8(2721600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(427 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0506072
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0480107
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0293943
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(427 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0106708 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0293943
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(2073600,32400:4,180,1) -> Int8(259200,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(440 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.116651
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0355474
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.026592
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(440 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00982645 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.026592
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(259200,32400:32,180,1) -> Int8(2073600,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(440 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0388526
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0350418
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0222563
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(440 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00918152 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0222563
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(453 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0620678
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0197286
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.014038
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(453 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0111467 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.014038
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(453 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0217306
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0194983
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0109714
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(453 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0118879 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0109714
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0592945
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0440194
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0427966
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00922743 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0427966
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0593829
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.044032
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0427611
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00982875 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0427611
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.126075
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0440423
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.126245
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0107417 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0440423
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0329079
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335662
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0429349
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0107869 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0329079
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0357966
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.038144
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0331282
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0103132 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0331282
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,1:2,11520,64) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0569905
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338798
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.057149
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0126912 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0338798
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0570027
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0332041
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0571063
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0099723 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0332041
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0570834
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338862
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0336375
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0102085 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0336375
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0570514
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331831
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0570514
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00949425 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331831
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0900389
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338395
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0899657
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00943051 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0338395
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0613516
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0443349
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0614217
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00986551 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0443349
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0436571
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0442103
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0436366
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0100674 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0436366
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0446171
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0455943
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0445143
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0101232 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0445143
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0602362
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0334619
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0600884
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00988904 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0334619
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(2073600,32400:2,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0613425
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.036168
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0613912
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00966829 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.036168
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(2073600,1:2,11520,64) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0400331
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0334117
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0400377
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0120276 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0334117
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0400423
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331712
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0399246
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00983731 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331712
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0399474
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337143
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0399726
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00985914 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337143
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(259200,1:16,1440,8) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0400034
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331621
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0399977
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0103232 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331621
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.126622
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0336576
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.126416
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0113761 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0336576
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529067
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338505
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529417
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00973854 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0338505
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0385463
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337627
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0385531
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0101218 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337627
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0412526
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.033589
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0412469
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00991422 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.033589
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.143945
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0341019
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.144238
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00935314 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0341019
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0516876
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0238933
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0516876
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0103145 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0238933
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(2073600,32400:2,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0289746
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.031744
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0289701
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0126812 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0289701
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(2073600,1:2,11520,64) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0366811
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0236774
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.03668
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0102675 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0236774
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.036664
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023439
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366914
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0111309 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.023439
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367086
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234442
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366811
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.0100023 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0234442
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(259200,1:16,1440,8) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 515) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367006
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0233881
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366697
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(<in> -> 515) (Reformat[0x80000006]) profiling completed in 0.00986339 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0233881
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0271604
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0288183
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.027379
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0105388 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0271604
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0381074
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0287433
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.027133
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0090242 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.027133
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.075808
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0291675
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.075776
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00741007 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0291675
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0669851
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0283352
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0668968
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0060832 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0283352
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0677272
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0299008
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0677303
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0057863 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0299008
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.115225
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.030432
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.115321
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.007938 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.030432
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0674271
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0286153
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0675352
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00768756 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0286153
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0677379
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0310885
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0678766
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00849078 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0310885
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.116224
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0318729
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.116517
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00630972 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0318729
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0588556
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0286016
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0587871
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00765826 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0286016
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0606552
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0300663
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0603672
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00947693 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0300663
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.110066
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0303086
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110197
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0101735 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0303086
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0181023
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181491
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0180846
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0107272 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0180846
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0395166
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0223889
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0395383
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00922002 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0223889
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0761851
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0198417
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0760686
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00931654 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0198417
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0392777
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221466
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0392491
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00893733 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0221466
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0235513
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0238987
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0236186
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0121345 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0235513
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0407451
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0209874
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0407714
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0101497 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0209874
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0586011
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0186566
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0585189
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0100256 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0186566
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.059875
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231236
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0597623
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00923587 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0231236
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.111113
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0202057
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.11125
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0102005 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0202057
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0584244
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0187377
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0584168
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00934038 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0187377
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0598796
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231242
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0598309
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00961101 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0231242
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.111177
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.02014
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.11125
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0102462 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.02014
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0583787
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0187
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.058563
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00913448 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0187
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0597714
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0215732
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0599101
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0111875 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0215732
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.111323
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0192851
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.111129
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0121559 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0192851
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0583756
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0186514
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0584244
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0122879 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0186514
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0599771
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214936
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0599771
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0103946 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0214936
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.111042
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0193663
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.11125
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0118372 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0193663
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Int8(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0556251
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0191486
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0555886
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0109579 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0191486
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0314807
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0204389
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0315054
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.0114814 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0204389
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0488884
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0186914
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0490057
[12/14/2023-17:14:07] [V] [TRT] QuantizeLinear_80 (Reformat[0x80000006]) profiling completed in 0.00972547 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0186914
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: QuantizeLinear_80 (MyelinReformat[0x80000035])
[12/14/2023-17:14:07] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[12/14/2023-17:14:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:07] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0593996
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0442629
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0427749
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0120358 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0427749
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0595977
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0440709
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0427966
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00921504 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0427966
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.057149
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0332654
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0342501
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0141037 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0332654
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0733851
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0444217
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0426377
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.012033 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0426377
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0442514
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0444629
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0432274
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0127178 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0432274
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0363589
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337317
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0363154
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0113201 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337317
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0733623
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0444503
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0425223
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0109829 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0425223
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.043192
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0443909
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0432183
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0129465 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.043192
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0394606
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331776
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0395703
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0109981 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331776
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0614507
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0443691
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0613425
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0129995 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0443691
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0436
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.04432
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0446503
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0138209 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0436
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0444709
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0443611
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0445063
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0139313 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0443611
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Float(129600,32400:32,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.040024
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0332416
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.040072
[12/14/2023-17:14:07] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0123969 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0332416
[12/14/2023-17:14:07] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0326446
[12/14/2023-17:14:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0340763
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0384069
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0115892 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0326446
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0590507
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338505
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0592731
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.012428 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0338505
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0587733
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0338587
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0587916
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0115628 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0338587
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0556373
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235801
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0287333
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0118887 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0235801
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0364229
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0334519
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0332791
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.011936 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0332791
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.045384
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0346295
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0454583
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0114066 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0346295
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0467383
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0346789
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.046808
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0145367 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0346789
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0407109
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0242674
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0276084
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0115179 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0242674
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.057635
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0334409
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0576853
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0120496 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0334409
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0372297
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337079
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.03728
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0122609 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337079
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.040448
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337691
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.040448
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00696702 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337691
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0362343
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235729
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0362434
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00994041 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0235729
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.057667
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331886
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.057539
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0103282 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331886
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0373189
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335835
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0373429
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0103646 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0335835
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.040448
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0334565
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0404606
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0104515 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0334565
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0361691
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235096
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0362354
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0123029 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0235096
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0576366
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0330743
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0324873
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0107446 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0324873
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0373566
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335506
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0373383
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00971984 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0335506
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0404114
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335287
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0405166
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00979984 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0335287
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0574415
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0331813
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0577326
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0106582 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0331813
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0373406
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335333
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0373829
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0100351 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0335333
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.040432
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0344064
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.040464
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0105264 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0344064
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0362206
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234691
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0363017
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0104222 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0234691
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(4147200,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529067
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0332891
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0528533
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0107096 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0332891
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(4147200,1,23040,128) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0385417
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0337106
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0385451
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0123163 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0337106
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Float(1036800,1:4,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0411463
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0335872
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0411314
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0107373 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0335872
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(129600,32400:32,180,1) -> Half(518400,1:8,2880,16) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367177
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0233626
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0367543
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(515 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0100436 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0233626
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0632731
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0636648
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0647147
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.0102922 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0632731
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.211529
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0653623
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.211529
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.0103059 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0653623
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.211968
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.065379
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.212101
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.0104159 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.065379
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.149943
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0438983
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.150089
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.00907686 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0438983
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0654385
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0635901
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0630491
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.0101687 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0630491
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.193536
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.064512
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.193243
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.00979049 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.064512
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.193536
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0644632
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.193682
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.00955669 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0644632
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 595) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.119442
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.044416
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.119662
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 595) (Reformat[0x80000006]) profiling completed in 0.0132946 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.044416
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(4147200,32400,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(518 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0448
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0196371
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0190394
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(518 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0115327 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0190394
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(4147200,32400,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(518 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0785851
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0185051
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0784823
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(518 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00959282 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0185051
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(1036800,32400:4,180,1) -> Int8(129600,32400:32,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(129600,32400:32,180,1) -> Int8(1036800,32400:4,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(531 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0346112
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.01091
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00750811
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(531 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0147008 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00750811
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(531 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111293
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010704
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490971
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(531 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0179918 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00490971
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(518400,8100:4,90,1) -> Int8(64800,8100:32,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Int8(64800,8100:32,90,1) -> Int8(518400,8100:4,90,1) ***************
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(607 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0632472
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0638293
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0801051
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(607 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00965146 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0632472
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(607 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.068413
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0688609
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0635855
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(607 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0106175 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0635855
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(607 -> <out>) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.127175
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0640823
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0630446
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(607 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0107281 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0630446
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs
[12/14/2023-17:14:08] [V] [TRT] =============== Computing reformatting costs: 
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 609) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0597821
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0679832
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0598232
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 609) (Reformat[0x80000006]) profiling completed in 0.0107316 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0597821
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 609) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0429714
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0443166
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0436777
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 609) (Reformat[0x80000006]) profiling completed in 0.00547227 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0429714
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 609) (Reformat[0x80000006])
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0598293
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0675352
[12/14/2023-17:14:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0597333
[12/14/2023-17:14:08] [V] [TRT] Optimizer Reformat(<in> -> 609) (Reformat[0x80000006]) profiling completed in 0.00679834 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0597333
[12/14/2023-17:14:08] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(16588800,32400,180,1) ***************
[12/14/2023-17:14:08] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_144 + Relu_145 (515) from Half(129600,32400:32,180,1) to Half(518400,1:8,2880,16)
[12/14/2023-17:14:08] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_144 + Relu_145 (595) from Half(2073600,1:8,11520,64) long-strided to Half(16588800,32400,180,1)
[12/14/2023-17:14:08] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to BatchNormalization_156 + Relu_157 (607) from Float(8294400,32400,180,1) to Half(8294400,32400,180,1)
[12/14/2023-17:14:08] [V] [TRT] Formats and tactics selection completed in 8.42267 seconds.
[12/14/2023-17:14:08] [V] [TRT] After reformat layers: 23 layers
[12/14/2023-17:14:08] [V] [TRT] Total number of blocks in pre-optimized block assignment: 21
[12/14/2023-17:14:08] [I] [TRT] Detected 2 inputs and 3 output network tensors.
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: Conv_144 + Relu_145 Host Persistent: 7200 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[12/14/2023-17:14:08] [V] [TRT] Layer: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 35373056
[12/14/2023-17:14:08] [V] [TRT] Skipped printing memory information for 8 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[12/14/2023-17:14:08] [I] [TRT] Total Host Persistent Memory: 75968
[12/14/2023-17:14:08] [I] [TRT] Total Device Persistent Memory: 0
[12/14/2023-17:14:08] [I] [TRT] Total Scratch Memory: 35373056
[12/14/2023-17:14:08] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 26 MiB, GPU 103 MiB
[12/14/2023-17:14:08] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 21 steps to complete.
[12/14/2023-17:14:08] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.093459ms to assign 3 blocks to 21 nodes requiring 72697856 bytes.
[12/14/2023-17:14:08] [V] [TRT] Total number of blocks in optimized block assignment: 3
[12/14/2023-17:14:08] [I] [TRT] Total Activation Memory: 72697856
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11 Set kernel index: 0
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22 Set kernel index: 1
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33 Set kernel index: 0
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44 Set kernel index: 0
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55 Set kernel index: 0
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66 Set kernel index: 0
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77 Set kernel index: 2
[12/14/2023-17:14:08] [V] [TRT] Finalize: Conv_144 + Relu_145 Set kernel index: 3
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88 Set kernel index: 4
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99 Set kernel index: 5
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110 Set kernel index: 5
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121 Set kernel index: 5
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132 Set kernel index: 5
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143 Set kernel index: 5
[12/14/2023-17:14:08] [V] [TRT] Finalize: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155 Set kernel index: 6
[12/14/2023-17:14:08] [V] [TRT] Total number of generated kernels selected for the engine: 7
[12/14/2023-17:14:08] [V] [TRT] Kernel: 0 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 1 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 2 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 3 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 4 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 5 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Kernel: 6 CASK_STATIC
[12/14/2023-17:14:08] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[12/14/2023-17:14:08] [V] [TRT] Engine generation completed in 8.51954 seconds.
[12/14/2023-17:14:08] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[12/14/2023-17:14:08] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[12/14/2023-17:14:08] [W] [TRT] Check verbose logs for the list of affected weights.
[12/14/2023-17:14:08] [W] [TRT] - 1 weights are affected by this issue: Detected subnormal FP16 values.
[12/14/2023-17:14:08] [V] [TRT]   List of affected weights: Conv_144 + Relu_145.weight
[12/14/2023-17:14:08] [V] [TRT] Deleting timing cache: 187 entries, served 45 hits since creation.
[12/14/2023-17:14:08] [V] [TRT] Engine Layer Information:
Layer(Reformat): QuantizeLinear_3_clone_1, Tactic: 0x00000000000003ea, lidar (Half[1,256,180,180]) -> 427 (Int8[1,256:32,180,180])
Layer(Reformat): QuantizeLinear_3_clone_0, Tactic: 0x00000000000003e8, camera (Half[1,80,180,180]) -> Concat_0_camera_clone_0 (Int8[1,80,180,180])
Layer(Reformat): Concat_0_camera_clone_0 copy, Tactic: 0x00000000000003ea, Concat_0_camera_clone_0 (Int8[1,80,180,180]) -> 427 (Int8[1,80:32,180,180])
Layer(CaskConvolution): parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11, Tactic: 0xf33711e7c9ed4673, 427 (Int8[1,336:32,180,180]) -> 440 (Int8[1,256:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22, Tactic: 0x70ccdad7e8ced9ab, 440 (Int8[1,256:32,180,180]) -> 453 (Int8[1,128:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33, Tactic: 0xf33711e7c9ed4673, 453 (Int8[1,128:32,180,180]) -> 466 (Int8[1,128:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44, Tactic: 0xf33711e7c9ed4673, 466 (Int8[1,128:32,180,180]) -> 479 (Int8[1,128:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55, Tactic: 0xf33711e7c9ed4673, 479 (Int8[1,128:32,180,180]) -> 492 (Int8[1,128:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66, Tactic: 0xf33711e7c9ed4673, 492 (Int8[1,128:32,180,180]) -> 505 (Int8[1,128:32,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77, Tactic: 0xad6872a374321f7e, 505 (Int8[1,128:32,180,180]) -> 515 (Half[1,128:32,180,180])
Layer(Reformat): QuantizeLinear_80, Tactic: 0x00000000000003ea, 515 (Half[1,128:32,180,180]) -> 518 (Int8[1,128:32,180,180])
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_144 + Relu_145, Tactic: 0x00000000000003ea, 515 (Half[1,128:32,180,180]) -> Reformatted Input Tensor 0 to Conv_144 + Relu_145 (Half[1,128:8,180,180])
Layer(CaskGemmConvolution): Conv_144 + Relu_145, Tactic: 0x000000000002077c, Reformatted Input Tensor 0 to Conv_144 + Relu_145 (Half[1,128:8,180,180]) -> Reformatted Output Tensor 0 to Conv_144 + Relu_145 (Half[1,256:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_144 + Relu_145, Tactic: 0x00000000000003ea, Reformatted Output Tensor 0 to Conv_144 + Relu_145 (Half[1,256:8,180,180]) -> middle (Half[1,256,180,180])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88, Tactic: 0x554e2e252e28b3fd, 518 (Int8[1,128:32,180,180]) -> 531 (Int8[1,256:32,90,90])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99, Tactic: 0xf8d4389f60adfa3c, 531 (Int8[1,256:32,90,90]) -> 544 (Int8[1,256:32,90,90])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110, Tactic: 0xf8d4389f60adfa3c, 544 (Int8[1,256:32,90,90]) -> 557 (Int8[1,256:32,90,90])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121, Tactic: 0xf8d4389f60adfa3c, 557 (Int8[1,256:32,90,90]) -> 570 (Int8[1,256:32,90,90])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132, Tactic: 0xf8d4389f60adfa3c, 570 (Int8[1,256:32,90,90]) -> 583 (Int8[1,256:32,90,90])
Layer(CaskConvolution): parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143, Tactic: 0xf8d4389f60adfa3c, 583 (Int8[1,256:32,90,90]) -> 598 (Int8[1,256:32,90,90])
Layer(CaskDeconvolution): parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155, Tactic: 0xa71946688cad8664, 598 (Int8[1,256:32,90,90]) -> 607 (Float[1,256,180,180])
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to BatchNormalization_156 + Relu_157, Tactic: 0x00000000000003e8, 607 (Float[1,256,180,180]) -> Reformatted Input Tensor 0 to BatchNormalization_156 + Relu_157 (Half[1,256,180,180])
Layer(Scale): BatchNormalization_156 + Relu_157, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to BatchNormalization_156 + Relu_157 (Half[1,256,180,180]) -> middle (Half[1,256,180,180])
[12/14/2023-17:14:08] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +5, GPU +6, now: CPU 5, GPU 6 (MiB)
[12/14/2023-17:14:08] [V] [TRT] Adding 1 engine(s) to plan file.
[12/14/2023-17:14:08] [I] Engine built in 15.0181 sec.
[12/14/2023-17:14:08] [I] [TRT] Loaded engine size: 6 MiB
[12/14/2023-17:14:08] [V] [TRT] Deserialization required 5578 microseconds.
[12/14/2023-17:14:08] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +5, now: CPU 0, GPU 5 (MiB)
[12/14/2023-17:14:08] [I] Engine deserialized in 0.00582204 sec.
[12/14/2023-17:14:08] [V] [TRT] Total per-runner device persistent memory is 0
[12/14/2023-17:14:08] [V] [TRT] Total per-runner host persistent memory is 75968
[12/14/2023-17:14:08] [V] [TRT] Allocated activation device memory of size 72697856
[12/14/2023-17:14:08] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +69, now: CPU 0, GPU 74 (MiB)
[12/14/2023-17:14:08] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[12/14/2023-17:14:08] [I] Setting persistentCacheLimit to 0 bytes.
[12/14/2023-17:14:08] [V] Using enqueueV3.
[12/14/2023-17:14:08] [I] Using random values for input camera
[12/14/2023-17:14:08] [I] Created input binding for camera with dimensions 1x80x180x180
[12/14/2023-17:14:08] [I] Using random values for input lidar
[12/14/2023-17:14:08] [I] Created input binding for lidar with dimensions 1x256x180x180
[12/14/2023-17:14:08] [I] Using random values for output middle
[12/14/2023-17:14:08] [I] Created output binding for middle with dimensions 1x512x180x180
[12/14/2023-17:14:08] [I] Layer Information:
[12/14/2023-17:14:08] [I] Layers:
Name: QuantizeLinear_3_clone_1, LayerType: Reformat, Inputs: [ { Name: lidar, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: 427, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: 
Name: QuantizeLinear_3_clone_0, LayerType: Reformat, Inputs: [ { Name: camera, Location: Device, Dimensions: [1,80,180,180], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Concat_0_camera_clone_0, Location: Device, Dimensions: [1,80,180,180], Format/Datatype: Row major Int8 format }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003e8, StreamId: 0, Metadata: 
Name: Concat_0_camera_clone_0 copy, LayerType: Reformat, Inputs: [ { Name: Concat_0_camera_clone_0, Location: Device, Dimensions: [1,80,180,180], Format/Datatype: Row major Int8 format }], Outputs: [ { Name: 427, Location: Device, Dimensions: [1,80,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Reformat, Origin: CONCAT, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: Concat_0]
Name: parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11, LayerType: CaskConvolution, Inputs: [ { Name: 427, Location: Device, Dimensions: [1,336,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 440, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 774144}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf33711e7c9ed4673, StreamId: 0, Metadata: [ONNX Layer: Conv_10][ONNX Layer: Relu_11]
Name: parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22, LayerType: CaskConvolution, Inputs: [ { Name: 440, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 453, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 294912}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x70ccdad7e8ced9ab, StreamId: 0, Metadata: [ONNX Layer: Conv_21][ONNX Layer: Relu_22]
Name: parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33, LayerType: CaskConvolution, Inputs: [ { Name: 453, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 466, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf33711e7c9ed4673, StreamId: 0, Metadata: [ONNX Layer: Conv_32][ONNX Layer: Relu_33]
Name: parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44, LayerType: CaskConvolution, Inputs: [ { Name: 466, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 479, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf33711e7c9ed4673, StreamId: 0, Metadata: [ONNX Layer: Conv_43][ONNX Layer: Relu_44]
Name: parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55, LayerType: CaskConvolution, Inputs: [ { Name: 479, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 492, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf33711e7c9ed4673, StreamId: 0, Metadata: [ONNX Layer: Conv_54][ONNX Layer: Relu_55]
Name: parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66, LayerType: CaskConvolution, Inputs: [ { Name: 492, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 505, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf33711e7c9ed4673, StreamId: 0, Metadata: [ONNX Layer: Conv_65][ONNX Layer: Relu_66]
Name: parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77, LayerType: CaskConvolution, Inputs: [ { Name: 505, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 515, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major FP16 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xad6872a374321f7e, StreamId: 0, Metadata: [ONNX Layer: Conv_76][ONNX Layer: Relu_77]
Name: QuantizeLinear_80, LayerType: Reformat, Inputs: [ { Name: 515, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major FP16 format }], Outputs: [ { Name: 518, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: 
Name: Reformatting CopyNode for Input Tensor 0 to Conv_144 + Relu_145, LayerType: Reformat, Inputs: [ { Name: 515, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 0 to Conv_144 + Relu_145, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: 
Name: Conv_144 + Relu_145, LayerType: CaskGemmConvolution, Inputs: [ { Name: Reformatted Input Tensor 0 to Conv_144 + Relu_145, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_144 + Relu_145, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 32768}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16, TacticValue: 0x000000000002077c, StreamId: 0, Metadata: [ONNX Layer: Conv_144][ONNX Layer: Relu_145]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_144 + Relu_145, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_144 + Relu_145, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: middle, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: 
Name: parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88, LayerType: CaskConvolution, Inputs: [ { Name: 518, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 531, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 294912}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x554e2e252e28b3fd, StreamId: 0, Metadata: [ONNX Layer: Conv_87][ONNX Layer: Relu_88]
Name: parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99, LayerType: CaskConvolution, Inputs: [ { Name: 531, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 544, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf8d4389f60adfa3c, StreamId: 0, Metadata: [ONNX Layer: Conv_98][ONNX Layer: Relu_99]
Name: parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110, LayerType: CaskConvolution, Inputs: [ { Name: 544, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 557, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf8d4389f60adfa3c, StreamId: 0, Metadata: [ONNX Layer: Conv_109][ONNX Layer: Relu_110]
Name: parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121, LayerType: CaskConvolution, Inputs: [ { Name: 557, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 570, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf8d4389f60adfa3c, StreamId: 0, Metadata: [ONNX Layer: Conv_120][ONNX Layer: Relu_121]
Name: parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132, LayerType: CaskConvolution, Inputs: [ { Name: 570, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 583, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf8d4389f60adfa3c, StreamId: 0, Metadata: [ONNX Layer: Conv_131][ONNX Layer: Relu_132]
Name: parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143, LayerType: CaskConvolution, Inputs: [ { Name: 583, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 598, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xf8d4389f60adfa3c, StreamId: 0, Metadata: [ONNX Layer: Conv_142][ONNX Layer: Relu_143]
Name: parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155, LayerType: CaskDeconvolution, Inputs: [ { Name: 598, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 607, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP32 }], ParameterType: Convolution, Kernel: [2,2], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 262144}, Bias: {"Type": "Float", "Count": 0}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 0, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1, TacticValue: 0xa71946688cad8664, StreamId: 0, Metadata: [ONNX Layer: ConvTranspose_155]
Name: Reformatting CopyNode for Input Tensor 0 to BatchNormalization_156 + Relu_157, LayerType: Reformat, Inputs: [ { Name: 607, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP32 }], Outputs: [ { Name: Reformatted Input Tensor 0 to BatchNormalization_156 + Relu_157, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x00000000000003e8, StreamId: 0, Metadata: 
Name: BatchNormalization_156 + Relu_157, LayerType: Scale, Inputs: [ { Name: Reformatted Input Tensor 0 to BatchNormalization_156 + Relu_157, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: middle, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Scale, Mode: CHANNEL, Shift: {"Type": "Half", "Count": 256}, Scale: {"Type": "Half", "Count": 256}, Power: {"Type": "Half", "Count": 0}, Activation: RELU, ChannelAxis: 1, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: BatchNormalization_156][ONNX Layer: Relu_157]

Bindings:
camera
lidar
middle
[12/14/2023-17:14:08] [I] Starting inference
[12/14/2023-17:14:12] [I] Warmup completed 58 queries over 200 ms
[12/14/2023-17:14:12] [I] Timing trace has 880 queries over 3.01145 s
[12/14/2023-17:14:12] [I] 
[12/14/2023-17:14:12] [I] === Trace details ===
[12/14/2023-17:14:12] [I] Trace averages of 10 runs:
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30437 ms - Host latency: 6.54136 ms (enqueue 0.143828 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30468 ms - Host latency: 6.59042 ms (enqueue 0.161487 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3041 ms - Host latency: 6.59163 ms (enqueue 0.158624 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30601 ms - Host latency: 6.60397 ms (enqueue 0.148926 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3098 ms - Host latency: 6.64034 ms (enqueue 0.14165 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30468 ms - Host latency: 6.66193 ms (enqueue 0.165155 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.4633 ms - Host latency: 6.72063 ms (enqueue 0.149023 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30786 ms - Host latency: 6.63239 ms (enqueue 0.144336 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30458 ms - Host latency: 6.57387 ms (enqueue 0.1358 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30435 ms - Host latency: 6.62053 ms (enqueue 0.131537 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30764 ms - Host latency: 6.66548 ms (enqueue 0.152631 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30724 ms - Host latency: 6.63346 ms (enqueue 0.176691 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30478 ms - Host latency: 6.5989 ms (enqueue 0.145892 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30399 ms - Host latency: 6.59476 ms (enqueue 0.12467 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30488 ms - Host latency: 6.6033 ms (enqueue 0.110187 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30928 ms - Host latency: 6.63376 ms (enqueue 0.111249 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30908 ms - Host latency: 6.71876 ms (enqueue 0.277924 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3056 ms - Host latency: 6.665 ms (enqueue 0.180756 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30613 ms - Host latency: 6.66744 ms (enqueue 0.137531 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30673 ms - Host latency: 6.63769 ms (enqueue 0.155408 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30673 ms - Host latency: 6.61131 ms (enqueue 0.121155 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30682 ms - Host latency: 6.61628 ms (enqueue 0.131647 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3098 ms - Host latency: 6.63343 ms (enqueue 0.140802 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30989 ms - Host latency: 6.64329 ms (enqueue 0.101904 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3065 ms - Host latency: 6.64646 ms (enqueue 0.114612 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30612 ms - Host latency: 6.66447 ms (enqueue 0.191711 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30553 ms - Host latency: 6.66284 ms (enqueue 0.186902 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30961 ms - Host latency: 6.65166 ms (enqueue 0.16377 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30613 ms - Host latency: 6.60369 ms (enqueue 0.132288 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30619 ms - Host latency: 6.64417 ms (enqueue 0.151038 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30599 ms - Host latency: 6.65287 ms (enqueue 0.127368 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3137 ms - Host latency: 6.63594 ms (enqueue 0.118689 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30771 ms - Host latency: 6.62875 ms (enqueue 0.111487 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30752 ms - Host latency: 6.65717 ms (enqueue 0.11991 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30499 ms - Host latency: 6.63684 ms (enqueue 0.109705 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30608 ms - Host latency: 6.61581 ms (enqueue 0.122986 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30724 ms - Host latency: 6.61548 ms (enqueue 0.129065 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31215 ms - Host latency: 6.60889 ms (enqueue 0.190503 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30588 ms - Host latency: 6.60095 ms (enqueue 0.18623 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30631 ms - Host latency: 6.63661 ms (enqueue 0.13916 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30469 ms - Host latency: 6.61614 ms (enqueue 0.119385 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31216 ms - Host latency: 6.61693 ms (enqueue 0.128784 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30796 ms - Host latency: 6.6329 ms (enqueue 0.124854 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30602 ms - Host latency: 6.58191 ms (enqueue 0.128809 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3057 ms - Host latency: 6.56133 ms (enqueue 0.114197 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30898 ms - Host latency: 6.62087 ms (enqueue 0.134656 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3092 ms - Host latency: 6.59246 ms (enqueue 0.137915 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30835 ms - Host latency: 6.63853 ms (enqueue 0.123828 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30797 ms - Host latency: 6.68469 ms (enqueue 0.145007 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31008 ms - Host latency: 6.65437 ms (enqueue 0.140234 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31104 ms - Host latency: 6.57902 ms (enqueue 0.120667 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.41692 ms - Host latency: 6.69839 ms (enqueue 0.151099 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30776 ms - Host latency: 6.65919 ms (enqueue 0.165039 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30774 ms - Host latency: 6.76945 ms (enqueue 0.276062 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31177 ms - Host latency: 6.74526 ms (enqueue 0.230127 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30781 ms - Host latency: 6.6458 ms (enqueue 0.151953 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.3063 ms - Host latency: 6.61826 ms (enqueue 0.160962 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30764 ms - Host latency: 6.63447 ms (enqueue 0.157446 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31052 ms - Host latency: 6.6009 ms (enqueue 0.12312 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30627 ms - Host latency: 6.58748 ms (enqueue 0.137158 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30464 ms - Host latency: 6.6124 ms (enqueue 0.187646 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30796 ms - Host latency: 6.64028 ms (enqueue 0.202881 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30918 ms - Host latency: 6.67842 ms (enqueue 0.23313 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30557 ms - Host latency: 6.60571 ms (enqueue 0.189258 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30544 ms - Host latency: 6.5751 ms (enqueue 0.181323 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30483 ms - Host latency: 6.6019 ms (enqueue 0.183569 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31003 ms - Host latency: 6.57959 ms (enqueue 0.17522 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30601 ms - Host latency: 6.59055 ms (enqueue 0.150928 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30789 ms - Host latency: 6.60042 ms (enqueue 0.170508 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30659 ms - Host latency: 6.61511 ms (enqueue 0.157104 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30764 ms - Host latency: 6.61919 ms (enqueue 0.123682 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30598 ms - Host latency: 6.59385 ms (enqueue 0.117236 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30645 ms - Host latency: 6.60562 ms (enqueue 0.136182 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30562 ms - Host latency: 6.59673 ms (enqueue 0.139111 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30525 ms - Host latency: 6.62759 ms (enqueue 0.134351 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31475 ms - Host latency: 6.58477 ms (enqueue 0.155127 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30718 ms - Host latency: 6.61077 ms (enqueue 0.139575 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30549 ms - Host latency: 6.6771 ms (enqueue 0.132031 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31099 ms - Host latency: 6.60054 ms (enqueue 0.135034 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30928 ms - Host latency: 6.6374 ms (enqueue 0.132031 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30615 ms - Host latency: 6.62642 ms (enqueue 0.116943 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30776 ms - Host latency: 6.61951 ms (enqueue 0.109692 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30774 ms - Host latency: 6.6533 ms (enqueue 0.147534 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31086 ms - Host latency: 6.62371 ms (enqueue 0.140039 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30554 ms - Host latency: 6.60361 ms (enqueue 0.117188 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30586 ms - Host latency: 6.62168 ms (enqueue 0.111816 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.30803 ms - Host latency: 6.63049 ms (enqueue 0.152954 ms)
[12/14/2023-17:14:12] [I] Average on 10 runs - GPU latency: 1.31069 ms - Host latency: 6.56645 ms (enqueue 0.200586 ms)
[12/14/2023-17:14:12] [I] 
[12/14/2023-17:14:12] [I] === Performance summary ===
[12/14/2023-17:14:12] [I] Throughput: 292.218 qps
[12/14/2023-17:14:12] [I] Latency: min = 6.26025 ms, max = 7.72809 ms, mean = 6.62726 ms, median = 6.62294 ms, percentile(90%) = 6.70776 ms, percentile(95%) = 6.75684 ms, percentile(99%) = 6.85852 ms
[12/14/2023-17:14:12] [I] Enqueue Time: min = 0.0908203 ms, max = 0.396423 ms, mean = 0.14873 ms, median = 0.137299 ms, percentile(90%) = 0.202393 ms, percentile(95%) = 0.232178 ms, percentile(99%) = 0.304504 ms
[12/14/2023-17:14:12] [I] H2D Latency: min = 1.72379 ms, max = 3.29639 ms, mean = 2.24912 ms, median = 2.2583 ms, percentile(90%) = 2.40167 ms, percentile(95%) = 2.43048 ms, percentile(99%) = 2.54871 ms
[12/14/2023-17:14:12] [I] GPU Compute Time: min = 1.29419 ms, max = 2.86719 ms, mean = 1.31039 ms, median = 1.30664 ms, percentile(90%) = 1.31274 ms, percentile(95%) = 1.31982 ms, percentile(99%) = 1.34351 ms
[12/14/2023-17:14:12] [I] D2H Latency: min = 2.6145 ms, max = 3.40607 ms, mean = 3.06775 ms, median = 3.08081 ms, percentile(90%) = 3.17188 ms, percentile(95%) = 3.1875 ms, percentile(99%) = 3.24194 ms
[12/14/2023-17:14:12] [I] Total Host Walltime: 3.01145 s
[12/14/2023-17:14:12] [I] Total GPU Compute Time: 1.15314 s
[12/14/2023-17:14:12] [W] * Throughput may be bound by host-to-device transfers for the inputs rather than GPU Compute and the GPU may be under-utilized.
[12/14/2023-17:14:12] [W]   Add --noDataTransfers flag to disable data transfers.
[12/14/2023-17:14:12] [W] * Throughput may be bound by device-to-host transfers for the outputs rather than GPU Compute and the GPU may be under-utilized.
[12/14/2023-17:14:12] [W]   Add --noDataTransfers flag to disable data transfers.
[12/14/2023-17:14:12] [W] * GPU compute time is unstable, with coefficient of variance = 4.90709%.
[12/14/2023-17:14:12] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[12/14/2023-17:14:12] [I] Explanations of the performance metrics are printed in the verbose logs.
[12/14/2023-17:14:12] [V] 
[12/14/2023-17:14:12] [V] === Explanations of the performance metrics ===
[12/14/2023-17:14:12] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[12/14/2023-17:14:12] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[12/14/2023-17:14:12] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/14/2023-17:14:12] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/14/2023-17:14:12] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[12/14/2023-17:14:12] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[12/14/2023-17:14:12] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[12/14/2023-17:14:12] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[12/14/2023-17:14:12] [I] 
[12/14/2023-17:14:15] [I] 
[12/14/2023-17:14:15] [I] === Profile (859 iterations ) ===
[12/14/2023-17:14:15] [I]                                                                                  Layer   Time (ms)   Avg. Time (ms)   Median Time (ms)   Time %
[12/14/2023-17:14:15] [I]                                                               QuantizeLinear_3_clone_1       33.72           0.0393             0.0389      2.9
[12/14/2023-17:14:15] [I]                                                               QuantizeLinear_3_clone_0       12.18           0.0142             0.0143      1.1
[12/14/2023-17:14:15] [I]                                                           Concat_0_camera_clone_0 copy       13.54           0.0158             0.0154      1.2
[12/14/2023-17:14:15] [I]                           parent.fuser.0.weight + QuantizeLinear_8 + Conv_10 + Relu_11      168.69           0.1964             0.1966     14.6
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.0.0.weight + QuantizeLinear_19 + Conv_21 + Relu_22       74.03           0.0862             0.0860      6.4
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.0.3.weight + QuantizeLinear_30 + Conv_32 + Relu_33       42.06           0.0490             0.0492      3.6
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.0.6.weight + QuantizeLinear_41 + Conv_43 + Relu_44       43.46           0.0506             0.0502      3.8
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.0.9.weight + QuantizeLinear_52 + Conv_54 + Relu_55       44.19           0.0514             0.0512      3.8
[12/14/2023-17:14:15] [I]     parent.decoder.backbone.blocks.0.12.weight + QuantizeLinear_63 + Conv_65 + Relu_66       44.29           0.0516             0.0512      3.8
[12/14/2023-17:14:15] [I]     parent.decoder.backbone.blocks.0.15.weight + QuantizeLinear_74 + Conv_76 + Relu_77       48.71           0.0567             0.0563      4.2
[12/14/2023-17:14:15] [I]                                                                      QuantizeLinear_80       17.81           0.0207             0.0205      1.5
[12/14/2023-17:14:15] [I]                        Reformatting CopyNode for Input Tensor 0 to Conv_144 + Relu_145       22.49           0.0262             0.0256      2.0
[12/14/2023-17:14:15] [I]                                                                    Conv_144 + Relu_145       38.27           0.0445             0.0440      3.3
[12/14/2023-17:14:15] [I]                       Reformatting CopyNode for Output Tensor 0 to Conv_144 + Relu_145       40.36           0.0470             0.0471      3.5
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.1.0.weight + QuantizeLinear_85 + Conv_87 + Relu_88       26.22           0.0305             0.0307      2.3
[12/14/2023-17:14:15] [I]      parent.decoder.backbone.blocks.1.3.weight + QuantizeLinear_96 + Conv_98 + Relu_99       41.45           0.0482             0.0481      3.6
[12/14/2023-17:14:15] [I]   parent.decoder.backbone.blocks.1.6.weight + QuantizeLinear_107 + Conv_109 + Relu_110       40.40           0.0470             0.0471      3.5
[12/14/2023-17:14:15] [I]   parent.decoder.backbone.blocks.1.9.weight + QuantizeLinear_118 + Conv_120 + Relu_121       40.09           0.0467             0.0471      3.5
[12/14/2023-17:14:15] [I]  parent.decoder.backbone.blocks.1.12.weight + QuantizeLinear_129 + Conv_131 + Relu_132       40.07           0.0467             0.0471      3.5
[12/14/2023-17:14:15] [I]  parent.decoder.backbone.blocks.1.15.weight + QuantizeLinear_140 + Conv_142 + Relu_143       39.94           0.0465             0.0461      3.5
[12/14/2023-17:14:15] [I]       parent.decoder.neck.deblocks.1.0.weight + QuantizeLinear_153 + ConvTranspose_155      186.08           0.2166             0.2161     16.1
[12/14/2023-17:14:15] [I]          Reformatting CopyNode for Input Tensor 0 to BatchNormalization_156 + Relu_157       55.49           0.0646             0.0645      4.8
[12/14/2023-17:14:15] [I]                                                      BatchNormalization_156 + Relu_157       39.04           0.0454             0.0451      3.4
[12/14/2023-17:14:15] [I]                                                                                  Total     1152.57           1.3418             1.3425    100.0
[12/14/2023-17:14:15] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8600] # trtexec --onnx=model/resnet50int8/fuser.onnx --fp16 --int8 --inputIOFormats=fp16:chw,fp16:chw, --outputIOFormats=fp16:chw, --saveEngine=model/resnet50int8/build/fuser.plan --memPoolSize=workspace:2048 --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed --exportLayerInfo=model/resnet50int8/build/fuser.json
